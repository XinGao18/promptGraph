{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.MF import *\n",
    "from preprocess.Yelp import *\n",
    "from evaluation.MF_evaluation import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/yelp2018'\n",
    "dataset = Yelp(path)\n",
    "\n",
    "# Data(num_nodes=144242, edge_index=[2, 2380730], edge_label_index=[2, 603378])\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'learning_rate': 1e-5,  # over-fitting\n",
    "    'epochs': 100,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    'global_bias':(data.edge_index.size(1) + data.edge_label_index.size(1) + 2) / (num_books * num_users)\n",
    "}\n",
    "model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578389b3510350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setting\n",
    "num_edges = data.edge_index.size(1)\n",
    "perm = torch.randperm(num_edges)\n",
    "split = int(num_edges * 0.1)  # 10% of edges will be retained\n",
    "\n",
    "# Define the data for forget and retain dataset\n",
    "forget_data = Data()\n",
    "retain_data = Data()\n",
    "\n",
    "forget_data.num_nodes = data.num_nodes\n",
    "retain_data.num_nodes = data.num_nodes\n",
    "forget_data.edge_index = data.edge_index[:, perm[:split]]\n",
    "retain_data.edge_index = data.edge_index[:, perm[split:]]\n",
    "forget_data.edge_label_index = data.edge_label_index\n",
    "retain_data.edge_label_index = data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4deecbfc691c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss: 0.9961, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 2/500, Train Loss: 0.9932, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 3/500, Train Loss: 0.9903, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 4/500, Train Loss: 0.9875, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 5/500, Train Loss: 0.9846, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 6/500, Train Loss: 0.9818, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 7/500, Train Loss: 0.9789, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 8/500, Train Loss: 0.9761, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 9/500, Train Loss: 0.9732, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 10/500, Train Loss: 0.9704, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 11/500, Train Loss: 0.9676, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 12/500, Train Loss: 0.9648, HR@20: 0.0004, Recall@20: 0.0007, NDCG@20: 0.0006\n",
      "Epoch 13/500, Train Loss: 0.9619, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 14/500, Train Loss: 0.9591, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 15/500, Train Loss: 0.9563, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 16/500, Train Loss: 0.9535, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0007\n",
      "Epoch 17/500, Train Loss: 0.9507, HR@20: 0.0004, Recall@20: 0.0009, NDCG@20: 0.0007\n",
      "Epoch 18/500, Train Loss: 0.9479, HR@20: 0.0005, Recall@20: 0.0010, NDCG@20: 0.0008\n",
      "Epoch 19/500, Train Loss: 0.9451, HR@20: 0.0006, Recall@20: 0.0011, NDCG@20: 0.0009\n",
      "Epoch 20/500, Train Loss: 0.9423, HR@20: 0.0006, Recall@20: 0.0012, NDCG@20: 0.0011\n",
      "Epoch 21/500, Train Loss: 0.9395, HR@20: 0.0007, Recall@20: 0.0014, NDCG@20: 0.0013\n",
      "Epoch 22/500, Train Loss: 0.9366, HR@20: 0.0009, Recall@20: 0.0016, NDCG@20: 0.0015\n",
      "Epoch 23/500, Train Loss: 0.9338, HR@20: 0.0010, Recall@20: 0.0019, NDCG@20: 0.0018\n",
      "Epoch 24/500, Train Loss: 0.9310, HR@20: 0.0013, Recall@20: 0.0024, NDCG@20: 0.0022\n",
      "Epoch 25/500, Train Loss: 0.9282, HR@20: 0.0016, Recall@20: 0.0029, NDCG@20: 0.0027\n",
      "Epoch 26/500, Train Loss: 0.9253, HR@20: 0.0020, Recall@20: 0.0036, NDCG@20: 0.0034\n",
      "Epoch 27/500, Train Loss: 0.9225, HR@20: 0.0024, Recall@20: 0.0045, NDCG@20: 0.0042\n",
      "Epoch 28/500, Train Loss: 0.9196, HR@20: 0.0030, Recall@20: 0.0055, NDCG@20: 0.0050\n",
      "Epoch 29/500, Train Loss: 0.9167, HR@20: 0.0036, Recall@20: 0.0066, NDCG@20: 0.0060\n",
      "Epoch 30/500, Train Loss: 0.9138, HR@20: 0.0041, Recall@20: 0.0077, NDCG@20: 0.0069\n",
      "Epoch 31/500, Train Loss: 0.9108, HR@20: 0.0048, Recall@20: 0.0090, NDCG@20: 0.0080\n",
      "Epoch 32/500, Train Loss: 0.9079, HR@20: 0.0054, Recall@20: 0.0104, NDCG@20: 0.0091\n",
      "Epoch 33/500, Train Loss: 0.9048, HR@20: 0.0061, Recall@20: 0.0118, NDCG@20: 0.0102\n",
      "Epoch 34/500, Train Loss: 0.9018, HR@20: 0.0067, Recall@20: 0.0130, NDCG@20: 0.0113\n",
      "Epoch 35/500, Train Loss: 0.8987, HR@20: 0.0073, Recall@20: 0.0144, NDCG@20: 0.0123\n",
      "Epoch 36/500, Train Loss: 0.8956, HR@20: 0.0079, Recall@20: 0.0157, NDCG@20: 0.0134\n",
      "Epoch 37/500, Train Loss: 0.8924, HR@20: 0.0085, Recall@20: 0.0170, NDCG@20: 0.0144\n",
      "Epoch 38/500, Train Loss: 0.8892, HR@20: 0.0091, Recall@20: 0.0182, NDCG@20: 0.0154\n",
      "Epoch 39/500, Train Loss: 0.8859, HR@20: 0.0097, Recall@20: 0.0194, NDCG@20: 0.0164\n",
      "Epoch 40/500, Train Loss: 0.8825, HR@20: 0.0102, Recall@20: 0.0205, NDCG@20: 0.0173\n",
      "Epoch 41/500, Train Loss: 0.8791, HR@20: 0.0107, Recall@20: 0.0215, NDCG@20: 0.0181\n",
      "Epoch 42/500, Train Loss: 0.8756, HR@20: 0.0111, Recall@20: 0.0225, NDCG@20: 0.0188\n",
      "Epoch 43/500, Train Loss: 0.8721, HR@20: 0.0115, Recall@20: 0.0234, NDCG@20: 0.0196\n",
      "Epoch 44/500, Train Loss: 0.8685, HR@20: 0.0119, Recall@20: 0.0244, NDCG@20: 0.0203\n",
      "Epoch 45/500, Train Loss: 0.8648, HR@20: 0.0122, Recall@20: 0.0250, NDCG@20: 0.0209\n",
      "Epoch 46/500, Train Loss: 0.8610, HR@20: 0.0126, Recall@20: 0.0259, NDCG@20: 0.0216\n",
      "Epoch 47/500, Train Loss: 0.8572, HR@20: 0.0129, Recall@20: 0.0265, NDCG@20: 0.0221\n",
      "Epoch 48/500, Train Loss: 0.8532, HR@20: 0.0131, Recall@20: 0.0271, NDCG@20: 0.0226\n",
      "Epoch 49/500, Train Loss: 0.8492, HR@20: 0.0135, Recall@20: 0.0279, NDCG@20: 0.0232\n",
      "Epoch 50/500, Train Loss: 0.8451, HR@20: 0.0137, Recall@20: 0.0283, NDCG@20: 0.0236\n",
      "Epoch 51/500, Train Loss: 0.8410, HR@20: 0.0139, Recall@20: 0.0288, NDCG@20: 0.0239\n",
      "Epoch 52/500, Train Loss: 0.8367, HR@20: 0.0140, Recall@20: 0.0291, NDCG@20: 0.0242\n",
      "Epoch 53/500, Train Loss: 0.8324, HR@20: 0.0142, Recall@20: 0.0295, NDCG@20: 0.0245\n",
      "Epoch 54/500, Train Loss: 0.8280, HR@20: 0.0143, Recall@20: 0.0299, NDCG@20: 0.0248\n",
      "Epoch 55/500, Train Loss: 0.8235, HR@20: 0.0144, Recall@20: 0.0302, NDCG@20: 0.0250\n",
      "Epoch 56/500, Train Loss: 0.8189, HR@20: 0.0146, Recall@20: 0.0305, NDCG@20: 0.0252\n",
      "Epoch 57/500, Train Loss: 0.8143, HR@20: 0.0147, Recall@20: 0.0308, NDCG@20: 0.0254\n",
      "Epoch 58/500, Train Loss: 0.8096, HR@20: 0.0148, Recall@20: 0.0310, NDCG@20: 0.0256\n",
      "Epoch 59/500, Train Loss: 0.8047, HR@20: 0.0149, Recall@20: 0.0313, NDCG@20: 0.0258\n",
      "Epoch 60/500, Train Loss: 0.7999, HR@20: 0.0149, Recall@20: 0.0314, NDCG@20: 0.0260\n",
      "Epoch 61/500, Train Loss: 0.7949, HR@20: 0.0150, Recall@20: 0.0317, NDCG@20: 0.0262\n",
      "Epoch 62/500, Train Loss: 0.7898, HR@20: 0.0151, Recall@20: 0.0318, NDCG@20: 0.0263\n",
      "Epoch 63/500, Train Loss: 0.7847, HR@20: 0.0151, Recall@20: 0.0319, NDCG@20: 0.0264\n",
      "Epoch 64/500, Train Loss: 0.7795, HR@20: 0.0151, Recall@20: 0.0320, NDCG@20: 0.0265\n",
      "Epoch 65/500, Train Loss: 0.7743, HR@20: 0.0151, Recall@20: 0.0321, NDCG@20: 0.0266\n",
      "Epoch 66/500, Train Loss: 0.7689, HR@20: 0.0152, Recall@20: 0.0322, NDCG@20: 0.0267\n",
      "Epoch 67/500, Train Loss: 0.7635, HR@20: 0.0153, Recall@20: 0.0324, NDCG@20: 0.0268\n",
      "Epoch 68/500, Train Loss: 0.7580, HR@20: 0.0153, Recall@20: 0.0324, NDCG@20: 0.0269\n",
      "Epoch 69/500, Train Loss: 0.7525, HR@20: 0.0153, Recall@20: 0.0324, NDCG@20: 0.0269\n",
      "Epoch 70/500, Train Loss: 0.7468, HR@20: 0.0153, Recall@20: 0.0325, NDCG@20: 0.0270\n",
      "Epoch 71/500, Train Loss: 0.7412, HR@20: 0.0154, Recall@20: 0.0325, NDCG@20: 0.0271\n",
      "Epoch 72/500, Train Loss: 0.7354, HR@20: 0.0154, Recall@20: 0.0326, NDCG@20: 0.0271\n",
      "Epoch 73/500, Train Loss: 0.7296, HR@20: 0.0154, Recall@20: 0.0326, NDCG@20: 0.0271\n",
      "Epoch 74/500, Train Loss: 0.7237, HR@20: 0.0154, Recall@20: 0.0327, NDCG@20: 0.0272\n",
      "Epoch 75/500, Train Loss: 0.7178, HR@20: 0.0155, Recall@20: 0.0327, NDCG@20: 0.0273\n",
      "Epoch 76/500, Train Loss: 0.7118, HR@20: 0.0155, Recall@20: 0.0328, NDCG@20: 0.0273\n",
      "Epoch 77/500, Train Loss: 0.7058, HR@20: 0.0155, Recall@20: 0.0328, NDCG@20: 0.0273\n",
      "Epoch 78/500, Train Loss: 0.6997, HR@20: 0.0155, Recall@20: 0.0329, NDCG@20: 0.0274\n",
      "Epoch 79/500, Train Loss: 0.6935, HR@20: 0.0155, Recall@20: 0.0329, NDCG@20: 0.0274\n",
      "Epoch 80/500, Train Loss: 0.6873, HR@20: 0.0155, Recall@20: 0.0329, NDCG@20: 0.0274\n",
      "Epoch 81/500, Train Loss: 0.6811, HR@20: 0.0155, Recall@20: 0.0330, NDCG@20: 0.0274\n",
      "Epoch 82/500, Train Loss: 0.6748, HR@20: 0.0156, Recall@20: 0.0331, NDCG@20: 0.0275\n",
      "Epoch 83/500, Train Loss: 0.6685, HR@20: 0.0156, Recall@20: 0.0331, NDCG@20: 0.0275\n",
      "Epoch 84/500, Train Loss: 0.6621, HR@20: 0.0156, Recall@20: 0.0331, NDCG@20: 0.0275\n",
      "Epoch 85/500, Train Loss: 0.6557, HR@20: 0.0156, Recall@20: 0.0331, NDCG@20: 0.0275\n",
      "Epoch 86/500, Train Loss: 0.6492, HR@20: 0.0156, Recall@20: 0.0332, NDCG@20: 0.0275\n",
      "Epoch 87/500, Train Loss: 0.6427, HR@20: 0.0156, Recall@20: 0.0332, NDCG@20: 0.0275\n",
      "Epoch 88/500, Train Loss: 0.6362, HR@20: 0.0156, Recall@20: 0.0332, NDCG@20: 0.0276\n",
      "Epoch 89/500, Train Loss: 0.6296, HR@20: 0.0156, Recall@20: 0.0332, NDCG@20: 0.0276\n",
      "Epoch 90/500, Train Loss: 0.6230, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0276\n",
      "Epoch 91/500, Train Loss: 0.6164, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0276\n",
      "Epoch 92/500, Train Loss: 0.6097, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0276\n",
      "Epoch 93/500, Train Loss: 0.6031, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0276\n",
      "Epoch 94/500, Train Loss: 0.5964, HR@20: 0.0156, Recall@20: 0.0334, NDCG@20: 0.0276\n",
      "Epoch 95/500, Train Loss: 0.5896, HR@20: 0.0157, Recall@20: 0.0334, NDCG@20: 0.0277\n",
      "Epoch 96/500, Train Loss: 0.5829, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0277\n",
      "Epoch 97/500, Train Loss: 0.5762, HR@20: 0.0157, Recall@20: 0.0334, NDCG@20: 0.0277\n",
      "Epoch 98/500, Train Loss: 0.5694, HR@20: 0.0157, Recall@20: 0.0334, NDCG@20: 0.0277\n",
      "Epoch 99/500, Train Loss: 0.5626, HR@20: 0.0157, Recall@20: 0.0334, NDCG@20: 0.0277\n",
      "Epoch 100/500, Train Loss: 0.5558, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0277\n",
      "Epoch 101/500, Train Loss: 0.5490, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0277\n",
      "Epoch 102/500, Train Loss: 0.5422, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0278\n",
      "Epoch 103/500, Train Loss: 0.5354, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0278\n",
      "Epoch 104/500, Train Loss: 0.5286, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0277\n",
      "Epoch 105/500, Train Loss: 0.5218, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0278\n",
      "Epoch 106/500, Train Loss: 0.5150, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0278\n",
      "Epoch 107/500, Train Loss: 0.5082, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0278\n",
      "Epoch 108/500, Train Loss: 0.5014, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0278\n",
      "Epoch 109/500, Train Loss: 0.4946, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0278\n",
      "Epoch 110/500, Train Loss: 0.4878, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 111/500, Train Loss: 0.4811, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 112/500, Train Loss: 0.4743, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 113/500, Train Loss: 0.4676, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 114/500, Train Loss: 0.4609, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 115/500, Train Loss: 0.4542, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 116/500, Train Loss: 0.4476, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 117/500, Train Loss: 0.4410, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 118/500, Train Loss: 0.4344, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 119/500, Train Loss: 0.4278, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 120/500, Train Loss: 0.4213, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 121/500, Train Loss: 0.4148, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0279\n",
      "Epoch 122/500, Train Loss: 0.4083, HR@20: 0.0158, Recall@20: 0.0336, NDCG@20: 0.0280\n",
      "Epoch 123/500, Train Loss: 0.4019, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 124/500, Train Loss: 0.3956, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 125/500, Train Loss: 0.3892, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 126/500, Train Loss: 0.3830, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 127/500, Train Loss: 0.3767, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 128/500, Train Loss: 0.3705, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 129/500, Train Loss: 0.3644, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0280\n",
      "Epoch 130/500, Train Loss: 0.3583, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0281\n",
      "Epoch 131/500, Train Loss: 0.3523, HR@20: 0.0158, Recall@20: 0.0337, NDCG@20: 0.0281\n",
      "Epoch 132/500, Train Loss: 0.3464, HR@20: 0.0158, Recall@20: 0.0338, NDCG@20: 0.0281\n",
      "Epoch 133/500, Train Loss: 0.3405, HR@20: 0.0158, Recall@20: 0.0338, NDCG@20: 0.0281\n",
      "Epoch 134/500, Train Loss: 0.3347, HR@20: 0.0158, Recall@20: 0.0338, NDCG@20: 0.0281\n",
      "Epoch 135/500, Train Loss: 0.3289, HR@20: 0.0159, Recall@20: 0.0339, NDCG@20: 0.0282\n",
      "Epoch 136/500, Train Loss: 0.3232, HR@20: 0.0159, Recall@20: 0.0339, NDCG@20: 0.0282\n",
      "Epoch 137/500, Train Loss: 0.3175, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0282\n",
      "Epoch 138/500, Train Loss: 0.3120, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0282\n",
      "Epoch 139/500, Train Loss: 0.3065, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0283\n",
      "Epoch 140/500, Train Loss: 0.3010, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0283\n",
      "Epoch 141/500, Train Loss: 0.2956, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0283\n",
      "Epoch 142/500, Train Loss: 0.2903, HR@20: 0.0159, Recall@20: 0.0340, NDCG@20: 0.0283\n",
      "Epoch 143/500, Train Loss: 0.2851, HR@20: 0.0159, Recall@20: 0.0341, NDCG@20: 0.0283\n",
      "Epoch 144/500, Train Loss: 0.2800, HR@20: 0.0159, Recall@20: 0.0341, NDCG@20: 0.0283\n",
      "Epoch 145/500, Train Loss: 0.2749, HR@20: 0.0159, Recall@20: 0.0341, NDCG@20: 0.0283\n",
      "Epoch 146/500, Train Loss: 0.2699, HR@20: 0.0159, Recall@20: 0.0341, NDCG@20: 0.0282\n",
      "Epoch 147/500, Train Loss: 0.2649, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0282\n",
      "Epoch 148/500, Train Loss: 0.2601, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0282\n",
      "Epoch 149/500, Train Loss: 0.2553, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0282\n",
      "Epoch 150/500, Train Loss: 0.2506, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0282\n",
      "Epoch 151/500, Train Loss: 0.2459, HR@20: 0.0159, Recall@20: 0.0341, NDCG@20: 0.0281\n",
      "Epoch 152/500, Train Loss: 0.2414, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0280\n",
      "Epoch 153/500, Train Loss: 0.2369, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0279\n",
      "Epoch 154/500, Train Loss: 0.2325, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0279\n",
      "Epoch 155/500, Train Loss: 0.2281, HR@20: 0.0159, Recall@20: 0.0342, NDCG@20: 0.0279\n",
      "Epoch 156/500, Train Loss: 0.2238, HR@20: 0.0159, Recall@20: 0.0343, NDCG@20: 0.0279\n",
      "Epoch 157/500, Train Loss: 0.2196, HR@20: 0.0159, Recall@20: 0.0343, NDCG@20: 0.0278\n",
      "Epoch 158/500, Train Loss: 0.2155, HR@20: 0.0159, Recall@20: 0.0343, NDCG@20: 0.0278\n",
      "Epoch 159/500, Train Loss: 0.2114, HR@20: 0.0159, Recall@20: 0.0343, NDCG@20: 0.0278\n",
      "Epoch 160/500, Train Loss: 0.2074, HR@20: 0.0159, Recall@20: 0.0344, NDCG@20: 0.0279\n",
      "Epoch 161/500, Train Loss: 0.2035, HR@20: 0.0159, Recall@20: 0.0344, NDCG@20: 0.0278\n",
      "Epoch 162/500, Train Loss: 0.1997, HR@20: 0.0159, Recall@20: 0.0344, NDCG@20: 0.0278\n",
      "Epoch 163/500, Train Loss: 0.1959, HR@20: 0.0159, Recall@20: 0.0344, NDCG@20: 0.0278\n",
      "Epoch 164/500, Train Loss: 0.1922, HR@20: 0.0158, Recall@20: 0.0342, NDCG@20: 0.0277\n",
      "Epoch 165/500, Train Loss: 0.1885, HR@20: 0.0158, Recall@20: 0.0341, NDCG@20: 0.0276\n",
      "Epoch 166/500, Train Loss: 0.1849, HR@20: 0.0158, Recall@20: 0.0340, NDCG@20: 0.0276\n",
      "Epoch 167/500, Train Loss: 0.1814, HR@20: 0.0157, Recall@20: 0.0340, NDCG@20: 0.0275\n",
      "Epoch 168/500, Train Loss: 0.1779, HR@20: 0.0157, Recall@20: 0.0339, NDCG@20: 0.0275\n",
      "Epoch 169/500, Train Loss: 0.1745, HR@20: 0.0157, Recall@20: 0.0339, NDCG@20: 0.0275\n",
      "Epoch 170/500, Train Loss: 0.1712, HR@20: 0.0158, Recall@20: 0.0340, NDCG@20: 0.0275\n",
      "Epoch 171/500, Train Loss: 0.1679, HR@20: 0.0157, Recall@20: 0.0340, NDCG@20: 0.0274\n",
      "Epoch 172/500, Train Loss: 0.1646, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0274\n",
      "Epoch 173/500, Train Loss: 0.1615, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0273\n",
      "Epoch 174/500, Train Loss: 0.1584, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0273\n",
      "Epoch 175/500, Train Loss: 0.1553, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0274\n",
      "Epoch 176/500, Train Loss: 0.1523, HR@20: 0.0157, Recall@20: 0.0337, NDCG@20: 0.0274\n",
      "Epoch 177/500, Train Loss: 0.1494, HR@20: 0.0157, Recall@20: 0.0337, NDCG@20: 0.0274\n",
      "Epoch 178/500, Train Loss: 0.1465, HR@20: 0.0157, Recall@20: 0.0337, NDCG@20: 0.0274\n",
      "Epoch 179/500, Train Loss: 0.1436, HR@20: 0.0157, Recall@20: 0.0337, NDCG@20: 0.0274\n",
      "Epoch 180/500, Train Loss: 0.1408, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0275\n",
      "Epoch 181/500, Train Loss: 0.1381, HR@20: 0.0157, Recall@20: 0.0338, NDCG@20: 0.0275\n",
      "Epoch 182/500, Train Loss: 0.1354, HR@20: 0.0157, Recall@20: 0.0337, NDCG@20: 0.0275\n",
      "Epoch 183/500, Train Loss: 0.1328, HR@20: 0.0157, Recall@20: 0.0336, NDCG@20: 0.0275\n",
      "Epoch 184/500, Train Loss: 0.1302, HR@20: 0.0157, Recall@20: 0.0335, NDCG@20: 0.0275\n",
      "Epoch 185/500, Train Loss: 0.1276, HR@20: 0.0157, Recall@20: 0.0334, NDCG@20: 0.0274\n",
      "Epoch 186/500, Train Loss: 0.1251, HR@20: 0.0156, Recall@20: 0.0334, NDCG@20: 0.0274\n",
      "Epoch 187/500, Train Loss: 0.1227, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0274\n",
      "Epoch 188/500, Train Loss: 0.1203, HR@20: 0.0156, Recall@20: 0.0333, NDCG@20: 0.0273\n",
      "Epoch 189/500, Train Loss: 0.1179, HR@20: 0.0156, Recall@20: 0.0332, NDCG@20: 0.0272\n",
      "Epoch 190/500, Train Loss: 0.1156, HR@20: 0.0155, Recall@20: 0.0330, NDCG@20: 0.0271\n",
      "Epoch 191/500, Train Loss: 0.1133, HR@20: 0.0155, Recall@20: 0.0329, NDCG@20: 0.0270\n",
      "Epoch 192/500, Train Loss: 0.1111, HR@20: 0.0154, Recall@20: 0.0327, NDCG@20: 0.0268\n",
      "Epoch 193/500, Train Loss: 0.1089, HR@20: 0.0153, Recall@20: 0.0324, NDCG@20: 0.0266\n",
      "Epoch 194/500, Train Loss: 0.1067, HR@20: 0.0153, Recall@20: 0.0323, NDCG@20: 0.0265\n",
      "Epoch 195/500, Train Loss: 0.1046, HR@20: 0.0152, Recall@20: 0.0321, NDCG@20: 0.0264\n",
      "Epoch 196/500, Train Loss: 0.1026, HR@20: 0.0151, Recall@20: 0.0320, NDCG@20: 0.0263\n",
      "Epoch 197/500, Train Loss: 0.1005, HR@20: 0.0151, Recall@20: 0.0319, NDCG@20: 0.0262\n",
      "Epoch 198/500, Train Loss: 0.0985, HR@20: 0.0150, Recall@20: 0.0317, NDCG@20: 0.0261\n",
      "Epoch 199/500, Train Loss: 0.0966, HR@20: 0.0150, Recall@20: 0.0317, NDCG@20: 0.0260\n",
      "Epoch 200/500, Train Loss: 0.0946, HR@20: 0.0149, Recall@20: 0.0314, NDCG@20: 0.0258\n",
      "Epoch 201/500, Train Loss: 0.0927, HR@20: 0.0148, Recall@20: 0.0313, NDCG@20: 0.0257\n",
      "Epoch 202/500, Train Loss: 0.0909, HR@20: 0.0147, Recall@20: 0.0311, NDCG@20: 0.0255\n",
      "Epoch 203/500, Train Loss: 0.0891, HR@20: 0.0147, Recall@20: 0.0310, NDCG@20: 0.0254\n",
      "Epoch 204/500, Train Loss: 0.0873, HR@20: 0.0146, Recall@20: 0.0308, NDCG@20: 0.0252\n",
      "Epoch 205/500, Train Loss: 0.0855, HR@20: 0.0145, Recall@20: 0.0305, NDCG@20: 0.0250\n",
      "Epoch 206/500, Train Loss: 0.0838, HR@20: 0.0143, Recall@20: 0.0303, NDCG@20: 0.0248\n",
      "Epoch 207/500, Train Loss: 0.0821, HR@20: 0.0142, Recall@20: 0.0301, NDCG@20: 0.0246\n",
      "Epoch 208/500, Train Loss: 0.0805, HR@20: 0.0141, Recall@20: 0.0299, NDCG@20: 0.0244\n",
      "Epoch 209/500, Train Loss: 0.0788, HR@20: 0.0140, Recall@20: 0.0297, NDCG@20: 0.0242\n",
      "Epoch 210/500, Train Loss: 0.0772, HR@20: 0.0139, Recall@20: 0.0294, NDCG@20: 0.0239\n",
      "Epoch 211/500, Train Loss: 0.0757, HR@20: 0.0137, Recall@20: 0.0292, NDCG@20: 0.0237\n",
      "Epoch 212/500, Train Loss: 0.0741, HR@20: 0.0136, Recall@20: 0.0289, NDCG@20: 0.0234\n",
      "Epoch 213/500, Train Loss: 0.0726, HR@20: 0.0135, Recall@20: 0.0287, NDCG@20: 0.0232\n",
      "Epoch 214/500, Train Loss: 0.0712, HR@20: 0.0133, Recall@20: 0.0282, NDCG@20: 0.0229\n",
      "Epoch 215/500, Train Loss: 0.0697, HR@20: 0.0131, Recall@20: 0.0279, NDCG@20: 0.0226\n",
      "Epoch 216/500, Train Loss: 0.0683, HR@20: 0.0129, Recall@20: 0.0275, NDCG@20: 0.0223\n",
      "Epoch 217/500, Train Loss: 0.0669, HR@20: 0.0128, Recall@20: 0.0271, NDCG@20: 0.0220\n",
      "Epoch 218/500, Train Loss: 0.0655, HR@20: 0.0126, Recall@20: 0.0267, NDCG@20: 0.0217\n",
      "Epoch 219/500, Train Loss: 0.0642, HR@20: 0.0124, Recall@20: 0.0263, NDCG@20: 0.0214\n",
      "Epoch 220/500, Train Loss: 0.0629, HR@20: 0.0122, Recall@20: 0.0260, NDCG@20: 0.0211\n",
      "Epoch 221/500, Train Loss: 0.0616, HR@20: 0.0121, Recall@20: 0.0255, NDCG@20: 0.0208\n",
      "Epoch 222/500, Train Loss: 0.0603, HR@20: 0.0119, Recall@20: 0.0252, NDCG@20: 0.0205\n",
      "Epoch 223/500, Train Loss: 0.0591, HR@20: 0.0118, Recall@20: 0.0249, NDCG@20: 0.0203\n",
      "Epoch 224/500, Train Loss: 0.0578, HR@20: 0.0117, Recall@20: 0.0247, NDCG@20: 0.0200\n",
      "Epoch 225/500, Train Loss: 0.0566, HR@20: 0.0116, Recall@20: 0.0245, NDCG@20: 0.0199\n",
      "Epoch 226/500, Train Loss: 0.0555, HR@20: 0.0115, Recall@20: 0.0242, NDCG@20: 0.0196\n",
      "Epoch 227/500, Train Loss: 0.0543, HR@20: 0.0113, Recall@20: 0.0240, NDCG@20: 0.0194\n",
      "Epoch 228/500, Train Loss: 0.0532, HR@20: 0.0112, Recall@20: 0.0237, NDCG@20: 0.0193\n",
      "Epoch 229/500, Train Loss: 0.0521, HR@20: 0.0111, Recall@20: 0.0235, NDCG@20: 0.0191\n",
      "Epoch 230/500, Train Loss: 0.0510, HR@20: 0.0110, Recall@20: 0.0234, NDCG@20: 0.0189\n",
      "Epoch 231/500, Train Loss: 0.0499, HR@20: 0.0109, Recall@20: 0.0232, NDCG@20: 0.0188\n",
      "Epoch 232/500, Train Loss: 0.0489, HR@20: 0.0108, Recall@20: 0.0228, NDCG@20: 0.0185\n",
      "Epoch 233/500, Train Loss: 0.0479, HR@20: 0.0107, Recall@20: 0.0226, NDCG@20: 0.0183\n",
      "Epoch 234/500, Train Loss: 0.0469, HR@20: 0.0106, Recall@20: 0.0223, NDCG@20: 0.0181\n",
      "Epoch 235/500, Train Loss: 0.0459, HR@20: 0.0105, Recall@20: 0.0222, NDCG@20: 0.0179\n",
      "Epoch 236/500, Train Loss: 0.0449, HR@20: 0.0103, Recall@20: 0.0218, NDCG@20: 0.0177\n",
      "Epoch 237/500, Train Loss: 0.0440, HR@20: 0.0102, Recall@20: 0.0215, NDCG@20: 0.0175\n",
      "Epoch 238/500, Train Loss: 0.0431, HR@20: 0.0101, Recall@20: 0.0213, NDCG@20: 0.0173\n",
      "Epoch 239/500, Train Loss: 0.0421, HR@20: 0.0100, Recall@20: 0.0210, NDCG@20: 0.0171\n",
      "Epoch 240/500, Train Loss: 0.0413, HR@20: 0.0099, Recall@20: 0.0208, NDCG@20: 0.0169\n",
      "Epoch 241/500, Train Loss: 0.0404, HR@20: 0.0098, Recall@20: 0.0205, NDCG@20: 0.0167\n",
      "Epoch 242/500, Train Loss: 0.0395, HR@20: 0.0097, Recall@20: 0.0202, NDCG@20: 0.0165\n",
      "Epoch 243/500, Train Loss: 0.0387, HR@20: 0.0096, Recall@20: 0.0201, NDCG@20: 0.0163\n",
      "Epoch 244/500, Train Loss: 0.0379, HR@20: 0.0095, Recall@20: 0.0199, NDCG@20: 0.0162\n",
      "Epoch 245/500, Train Loss: 0.0371, HR@20: 0.0094, Recall@20: 0.0198, NDCG@20: 0.0160\n",
      "Epoch 246/500, Train Loss: 0.0363, HR@20: 0.0094, Recall@20: 0.0196, NDCG@20: 0.0159\n",
      "Epoch 247/500, Train Loss: 0.0355, HR@20: 0.0093, Recall@20: 0.0194, NDCG@20: 0.0157\n",
      "Epoch 248/500, Train Loss: 0.0347, HR@20: 0.0092, Recall@20: 0.0192, NDCG@20: 0.0156\n",
      "Epoch 249/500, Train Loss: 0.0340, HR@20: 0.0091, Recall@20: 0.0190, NDCG@20: 0.0154\n",
      "Epoch 250/500, Train Loss: 0.0333, HR@20: 0.0090, Recall@20: 0.0188, NDCG@20: 0.0152\n",
      "Epoch 251/500, Train Loss: 0.0325, HR@20: 0.0089, Recall@20: 0.0186, NDCG@20: 0.0150\n",
      "Epoch 252/500, Train Loss: 0.0318, HR@20: 0.0088, Recall@20: 0.0184, NDCG@20: 0.0148\n",
      "Epoch 253/500, Train Loss: 0.0312, HR@20: 0.0088, Recall@20: 0.0183, NDCG@20: 0.0147\n",
      "Epoch 254/500, Train Loss: 0.0305, HR@20: 0.0087, Recall@20: 0.0181, NDCG@20: 0.0146\n",
      "Epoch 255/500, Train Loss: 0.0298, HR@20: 0.0086, Recall@20: 0.0179, NDCG@20: 0.0144\n",
      "Epoch 256/500, Train Loss: 0.0292, HR@20: 0.0085, Recall@20: 0.0178, NDCG@20: 0.0143\n",
      "Epoch 257/500, Train Loss: 0.0286, HR@20: 0.0085, Recall@20: 0.0176, NDCG@20: 0.0141\n",
      "Epoch 258/500, Train Loss: 0.0279, HR@20: 0.0084, Recall@20: 0.0174, NDCG@20: 0.0140\n",
      "Epoch 259/500, Train Loss: 0.0273, HR@20: 0.0083, Recall@20: 0.0171, NDCG@20: 0.0137\n",
      "Epoch 260/500, Train Loss: 0.0267, HR@20: 0.0082, Recall@20: 0.0169, NDCG@20: 0.0136\n",
      "Epoch 261/500, Train Loss: 0.0261, HR@20: 0.0081, Recall@20: 0.0167, NDCG@20: 0.0134\n",
      "Epoch 262/500, Train Loss: 0.0256, HR@20: 0.0080, Recall@20: 0.0166, NDCG@20: 0.0133\n",
      "Epoch 263/500, Train Loss: 0.0250, HR@20: 0.0078, Recall@20: 0.0163, NDCG@20: 0.0131\n",
      "Epoch 264/500, Train Loss: 0.0245, HR@20: 0.0078, Recall@20: 0.0162, NDCG@20: 0.0130\n",
      "Epoch 265/500, Train Loss: 0.0239, HR@20: 0.0077, Recall@20: 0.0160, NDCG@20: 0.0128\n",
      "Epoch 266/500, Train Loss: 0.0234, HR@20: 0.0076, Recall@20: 0.0159, NDCG@20: 0.0127\n",
      "Epoch 267/500, Train Loss: 0.0229, HR@20: 0.0075, Recall@20: 0.0157, NDCG@20: 0.0125\n",
      "Epoch 268/500, Train Loss: 0.0224, HR@20: 0.0074, Recall@20: 0.0156, NDCG@20: 0.0124\n",
      "Epoch 269/500, Train Loss: 0.0219, HR@20: 0.0073, Recall@20: 0.0154, NDCG@20: 0.0122\n",
      "Epoch 270/500, Train Loss: 0.0214, HR@20: 0.0072, Recall@20: 0.0152, NDCG@20: 0.0120\n",
      "Epoch 271/500, Train Loss: 0.0209, HR@20: 0.0071, Recall@20: 0.0151, NDCG@20: 0.0119\n",
      "Epoch 272/500, Train Loss: 0.0205, HR@20: 0.0071, Recall@20: 0.0149, NDCG@20: 0.0118\n",
      "Epoch 273/500, Train Loss: 0.0200, HR@20: 0.0070, Recall@20: 0.0147, NDCG@20: 0.0116\n",
      "Epoch 274/500, Train Loss: 0.0196, HR@20: 0.0069, Recall@20: 0.0144, NDCG@20: 0.0114\n",
      "Epoch 275/500, Train Loss: 0.0191, HR@20: 0.0068, Recall@20: 0.0143, NDCG@20: 0.0113\n",
      "Epoch 276/500, Train Loss: 0.0187, HR@20: 0.0067, Recall@20: 0.0140, NDCG@20: 0.0111\n",
      "Epoch 277/500, Train Loss: 0.0183, HR@20: 0.0066, Recall@20: 0.0139, NDCG@20: 0.0110\n",
      "Epoch 278/500, Train Loss: 0.0179, HR@20: 0.0066, Recall@20: 0.0138, NDCG@20: 0.0109\n",
      "Epoch 279/500, Train Loss: 0.0175, HR@20: 0.0065, Recall@20: 0.0136, NDCG@20: 0.0108\n",
      "Epoch 280/500, Train Loss: 0.0171, HR@20: 0.0065, Recall@20: 0.0135, NDCG@20: 0.0106\n",
      "Epoch 281/500, Train Loss: 0.0167, HR@20: 0.0064, Recall@20: 0.0133, NDCG@20: 0.0104\n",
      "Epoch 282/500, Train Loss: 0.0163, HR@20: 0.0063, Recall@20: 0.0132, NDCG@20: 0.0104\n",
      "Epoch 283/500, Train Loss: 0.0160, HR@20: 0.0063, Recall@20: 0.0131, NDCG@20: 0.0103\n",
      "Epoch 284/500, Train Loss: 0.0156, HR@20: 0.0062, Recall@20: 0.0130, NDCG@20: 0.0102\n",
      "Epoch 285/500, Train Loss: 0.0153, HR@20: 0.0062, Recall@20: 0.0129, NDCG@20: 0.0101\n",
      "Epoch 286/500, Train Loss: 0.0149, HR@20: 0.0061, Recall@20: 0.0126, NDCG@20: 0.0099\n",
      "Epoch 287/500, Train Loss: 0.0146, HR@20: 0.0060, Recall@20: 0.0125, NDCG@20: 0.0099\n",
      "Epoch 288/500, Train Loss: 0.0143, HR@20: 0.0059, Recall@20: 0.0124, NDCG@20: 0.0097\n",
      "Epoch 289/500, Train Loss: 0.0139, HR@20: 0.0059, Recall@20: 0.0123, NDCG@20: 0.0096\n",
      "Epoch 290/500, Train Loss: 0.0136, HR@20: 0.0058, Recall@20: 0.0123, NDCG@20: 0.0095\n",
      "Epoch 291/500, Train Loss: 0.0133, HR@20: 0.0058, Recall@20: 0.0121, NDCG@20: 0.0094\n",
      "Epoch 292/500, Train Loss: 0.0130, HR@20: 0.0057, Recall@20: 0.0121, NDCG@20: 0.0093\n",
      "Epoch 293/500, Train Loss: 0.0127, HR@20: 0.0057, Recall@20: 0.0119, NDCG@20: 0.0092\n",
      "Epoch 294/500, Train Loss: 0.0124, HR@20: 0.0056, Recall@20: 0.0118, NDCG@20: 0.0091\n",
      "Epoch 295/500, Train Loss: 0.0122, HR@20: 0.0055, Recall@20: 0.0116, NDCG@20: 0.0090\n",
      "Epoch 296/500, Train Loss: 0.0119, HR@20: 0.0054, Recall@20: 0.0115, NDCG@20: 0.0088\n",
      "Epoch 297/500, Train Loss: 0.0116, HR@20: 0.0054, Recall@20: 0.0114, NDCG@20: 0.0088\n",
      "Epoch 298/500, Train Loss: 0.0114, HR@20: 0.0053, Recall@20: 0.0113, NDCG@20: 0.0087\n",
      "Epoch 299/500, Train Loss: 0.0111, HR@20: 0.0053, Recall@20: 0.0111, NDCG@20: 0.0086\n",
      "Epoch 300/500, Train Loss: 0.0108, HR@20: 0.0052, Recall@20: 0.0110, NDCG@20: 0.0086\n",
      "Epoch 301/500, Train Loss: 0.0106, HR@20: 0.0052, Recall@20: 0.0109, NDCG@20: 0.0085\n",
      "Epoch 302/500, Train Loss: 0.0104, HR@20: 0.0051, Recall@20: 0.0108, NDCG@20: 0.0084\n",
      "Epoch 303/500, Train Loss: 0.0101, HR@20: 0.0051, Recall@20: 0.0107, NDCG@20: 0.0083\n",
      "Epoch 304/500, Train Loss: 0.0099, HR@20: 0.0050, Recall@20: 0.0106, NDCG@20: 0.0082\n",
      "Epoch 305/500, Train Loss: 0.0097, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0081\n",
      "Epoch 306/500, Train Loss: 0.0095, HR@20: 0.0049, Recall@20: 0.0103, NDCG@20: 0.0080\n",
      "Epoch 307/500, Train Loss: 0.0092, HR@20: 0.0048, Recall@20: 0.0102, NDCG@20: 0.0079\n",
      "Epoch 308/500, Train Loss: 0.0090, HR@20: 0.0048, Recall@20: 0.0100, NDCG@20: 0.0078\n",
      "Epoch 309/500, Train Loss: 0.0088, HR@20: 0.0047, Recall@20: 0.0099, NDCG@20: 0.0077\n",
      "Epoch 310/500, Train Loss: 0.0086, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0076\n",
      "Epoch 311/500, Train Loss: 0.0084, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0075\n",
      "Epoch 312/500, Train Loss: 0.0082, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0074\n",
      "Epoch 313/500, Train Loss: 0.0081, HR@20: 0.0044, Recall@20: 0.0094, NDCG@20: 0.0074\n",
      "Epoch 314/500, Train Loss: 0.0079, HR@20: 0.0044, Recall@20: 0.0093, NDCG@20: 0.0073\n",
      "Epoch 315/500, Train Loss: 0.0077, HR@20: 0.0044, Recall@20: 0.0093, NDCG@20: 0.0072\n",
      "Epoch 316/500, Train Loss: 0.0075, HR@20: 0.0043, Recall@20: 0.0092, NDCG@20: 0.0072\n",
      "Epoch 317/500, Train Loss: 0.0074, HR@20: 0.0043, Recall@20: 0.0091, NDCG@20: 0.0071\n",
      "Epoch 318/500, Train Loss: 0.0072, HR@20: 0.0042, Recall@20: 0.0090, NDCG@20: 0.0070\n",
      "Epoch 319/500, Train Loss: 0.0070, HR@20: 0.0042, Recall@20: 0.0089, NDCG@20: 0.0069\n",
      "Epoch 320/500, Train Loss: 0.0069, HR@20: 0.0041, Recall@20: 0.0087, NDCG@20: 0.0068\n",
      "Epoch 321/500, Train Loss: 0.0067, HR@20: 0.0040, Recall@20: 0.0085, NDCG@20: 0.0067\n",
      "Epoch 322/500, Train Loss: 0.0066, HR@20: 0.0040, Recall@20: 0.0085, NDCG@20: 0.0067\n",
      "Epoch 323/500, Train Loss: 0.0064, HR@20: 0.0040, Recall@20: 0.0084, NDCG@20: 0.0066\n",
      "Epoch 324/500, Train Loss: 0.0063, HR@20: 0.0039, Recall@20: 0.0083, NDCG@20: 0.0065\n",
      "Epoch 325/500, Train Loss: 0.0061, HR@20: 0.0039, Recall@20: 0.0082, NDCG@20: 0.0065\n",
      "Epoch 326/500, Train Loss: 0.0060, HR@20: 0.0038, Recall@20: 0.0082, NDCG@20: 0.0064\n",
      "Epoch 327/500, Train Loss: 0.0059, HR@20: 0.0038, Recall@20: 0.0080, NDCG@20: 0.0063\n",
      "Epoch 328/500, Train Loss: 0.0057, HR@20: 0.0037, Recall@20: 0.0079, NDCG@20: 0.0062\n",
      "Epoch 329/500, Train Loss: 0.0056, HR@20: 0.0037, Recall@20: 0.0078, NDCG@20: 0.0062\n",
      "Epoch 330/500, Train Loss: 0.0055, HR@20: 0.0036, Recall@20: 0.0076, NDCG@20: 0.0061\n",
      "Epoch 331/500, Train Loss: 0.0054, HR@20: 0.0036, Recall@20: 0.0076, NDCG@20: 0.0060\n",
      "Epoch 332/500, Train Loss: 0.0053, HR@20: 0.0035, Recall@20: 0.0075, NDCG@20: 0.0059\n",
      "Epoch 333/500, Train Loss: 0.0051, HR@20: 0.0035, Recall@20: 0.0074, NDCG@20: 0.0058\n",
      "Epoch 334/500, Train Loss: 0.0050, HR@20: 0.0034, Recall@20: 0.0073, NDCG@20: 0.0057\n",
      "Epoch 335/500, Train Loss: 0.0049, HR@20: 0.0034, Recall@20: 0.0072, NDCG@20: 0.0057\n",
      "Epoch 336/500, Train Loss: 0.0048, HR@20: 0.0034, Recall@20: 0.0071, NDCG@20: 0.0056\n",
      "Epoch 337/500, Train Loss: 0.0047, HR@20: 0.0033, Recall@20: 0.0070, NDCG@20: 0.0055\n",
      "Epoch 338/500, Train Loss: 0.0046, HR@20: 0.0033, Recall@20: 0.0070, NDCG@20: 0.0055\n",
      "Epoch 339/500, Train Loss: 0.0045, HR@20: 0.0032, Recall@20: 0.0069, NDCG@20: 0.0054\n",
      "Epoch 340/500, Train Loss: 0.0044, HR@20: 0.0032, Recall@20: 0.0069, NDCG@20: 0.0053\n",
      "Epoch 341/500, Train Loss: 0.0043, HR@20: 0.0032, Recall@20: 0.0068, NDCG@20: 0.0053\n",
      "Epoch 342/500, Train Loss: 0.0042, HR@20: 0.0032, Recall@20: 0.0068, NDCG@20: 0.0052\n",
      "Epoch 343/500, Train Loss: 0.0041, HR@20: 0.0031, Recall@20: 0.0067, NDCG@20: 0.0052\n",
      "Epoch 344/500, Train Loss: 0.0041, HR@20: 0.0031, Recall@20: 0.0066, NDCG@20: 0.0051\n",
      "Epoch 345/500, Train Loss: 0.0040, HR@20: 0.0031, Recall@20: 0.0065, NDCG@20: 0.0050\n",
      "Epoch 346/500, Train Loss: 0.0039, HR@20: 0.0030, Recall@20: 0.0064, NDCG@20: 0.0049\n",
      "Epoch 347/500, Train Loss: 0.0038, HR@20: 0.0030, Recall@20: 0.0063, NDCG@20: 0.0049\n",
      "Epoch 348/500, Train Loss: 0.0037, HR@20: 0.0030, Recall@20: 0.0062, NDCG@20: 0.0048\n",
      "Epoch 349/500, Train Loss: 0.0037, HR@20: 0.0029, Recall@20: 0.0061, NDCG@20: 0.0048\n",
      "Epoch 350/500, Train Loss: 0.0036, HR@20: 0.0029, Recall@20: 0.0060, NDCG@20: 0.0047\n",
      "Epoch 351/500, Train Loss: 0.0035, HR@20: 0.0029, Recall@20: 0.0060, NDCG@20: 0.0047\n",
      "Epoch 352/500, Train Loss: 0.0034, HR@20: 0.0029, Recall@20: 0.0059, NDCG@20: 0.0046\n",
      "Epoch 353/500, Train Loss: 0.0034, HR@20: 0.0028, Recall@20: 0.0058, NDCG@20: 0.0045\n",
      "Epoch 354/500, Train Loss: 0.0033, HR@20: 0.0028, Recall@20: 0.0058, NDCG@20: 0.0045\n",
      "Epoch 355/500, Train Loss: 0.0032, HR@20: 0.0028, Recall@20: 0.0057, NDCG@20: 0.0045\n",
      "Epoch 356/500, Train Loss: 0.0032, HR@20: 0.0028, Recall@20: 0.0057, NDCG@20: 0.0044\n",
      "Epoch 357/500, Train Loss: 0.0031, HR@20: 0.0027, Recall@20: 0.0056, NDCG@20: 0.0044\n",
      "Epoch 358/500, Train Loss: 0.0030, HR@20: 0.0027, Recall@20: 0.0055, NDCG@20: 0.0043\n",
      "Epoch 359/500, Train Loss: 0.0030, HR@20: 0.0026, Recall@20: 0.0055, NDCG@20: 0.0043\n",
      "Epoch 360/500, Train Loss: 0.0029, HR@20: 0.0026, Recall@20: 0.0055, NDCG@20: 0.0042\n",
      "Epoch 361/500, Train Loss: 0.0029, HR@20: 0.0026, Recall@20: 0.0054, NDCG@20: 0.0042\n",
      "Epoch 362/500, Train Loss: 0.0028, HR@20: 0.0026, Recall@20: 0.0053, NDCG@20: 0.0041\n",
      "Epoch 363/500, Train Loss: 0.0028, HR@20: 0.0025, Recall@20: 0.0053, NDCG@20: 0.0041\n",
      "Epoch 364/500, Train Loss: 0.0027, HR@20: 0.0025, Recall@20: 0.0052, NDCG@20: 0.0041\n",
      "Epoch 365/500, Train Loss: 0.0027, HR@20: 0.0025, Recall@20: 0.0051, NDCG@20: 0.0040\n",
      "Epoch 366/500, Train Loss: 0.0026, HR@20: 0.0025, Recall@20: 0.0051, NDCG@20: 0.0040\n",
      "Epoch 367/500, Train Loss: 0.0026, HR@20: 0.0024, Recall@20: 0.0050, NDCG@20: 0.0040\n",
      "Epoch 368/500, Train Loss: 0.0025, HR@20: 0.0024, Recall@20: 0.0050, NDCG@20: 0.0040\n",
      "Epoch 369/500, Train Loss: 0.0025, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0039\n",
      "Epoch 370/500, Train Loss: 0.0024, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0039\n",
      "Epoch 371/500, Train Loss: 0.0024, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0039\n",
      "Epoch 372/500, Train Loss: 0.0023, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0038\n",
      "Epoch 373/500, Train Loss: 0.0023, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0038\n",
      "Epoch 374/500, Train Loss: 0.0022, HR@20: 0.0024, Recall@20: 0.0049, NDCG@20: 0.0038\n",
      "Epoch 375/500, Train Loss: 0.0022, HR@20: 0.0023, Recall@20: 0.0048, NDCG@20: 0.0038\n",
      "Epoch 376/500, Train Loss: 0.0022, HR@20: 0.0023, Recall@20: 0.0048, NDCG@20: 0.0037\n",
      "Epoch 377/500, Train Loss: 0.0021, HR@20: 0.0023, Recall@20: 0.0047, NDCG@20: 0.0037\n",
      "Epoch 378/500, Train Loss: 0.0021, HR@20: 0.0023, Recall@20: 0.0047, NDCG@20: 0.0037\n",
      "Epoch 379/500, Train Loss: 0.0020, HR@20: 0.0023, Recall@20: 0.0047, NDCG@20: 0.0037\n",
      "Epoch 380/500, Train Loss: 0.0020, HR@20: 0.0023, Recall@20: 0.0047, NDCG@20: 0.0037\n",
      "Epoch 381/500, Train Loss: 0.0020, HR@20: 0.0023, Recall@20: 0.0047, NDCG@20: 0.0037\n",
      "Epoch 382/500, Train Loss: 0.0019, HR@20: 0.0022, Recall@20: 0.0046, NDCG@20: 0.0036\n",
      "Epoch 383/500, Train Loss: 0.0019, HR@20: 0.0022, Recall@20: 0.0046, NDCG@20: 0.0036\n",
      "Epoch 384/500, Train Loss: 0.0019, HR@20: 0.0022, Recall@20: 0.0046, NDCG@20: 0.0036\n",
      "Epoch 385/500, Train Loss: 0.0018, HR@20: 0.0022, Recall@20: 0.0045, NDCG@20: 0.0035\n",
      "Epoch 386/500, Train Loss: 0.0018, HR@20: 0.0022, Recall@20: 0.0045, NDCG@20: 0.0035\n",
      "Epoch 387/500, Train Loss: 0.0018, HR@20: 0.0022, Recall@20: 0.0044, NDCG@20: 0.0035\n",
      "Epoch 388/500, Train Loss: 0.0018, HR@20: 0.0022, Recall@20: 0.0044, NDCG@20: 0.0035\n",
      "Epoch 389/500, Train Loss: 0.0017, HR@20: 0.0021, Recall@20: 0.0044, NDCG@20: 0.0034\n",
      "Epoch 390/500, Train Loss: 0.0017, HR@20: 0.0021, Recall@20: 0.0044, NDCG@20: 0.0034\n",
      "Epoch 391/500, Train Loss: 0.0017, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0034\n",
      "Epoch 392/500, Train Loss: 0.0016, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0034\n",
      "Epoch 393/500, Train Loss: 0.0016, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0034\n",
      "Epoch 394/500, Train Loss: 0.0016, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0033\n",
      "Epoch 395/500, Train Loss: 0.0016, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0033\n",
      "Epoch 396/500, Train Loss: 0.0015, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0033\n",
      "Epoch 397/500, Train Loss: 0.0015, HR@20: 0.0021, Recall@20: 0.0042, NDCG@20: 0.0033\n",
      "Epoch 398/500, Train Loss: 0.0015, HR@20: 0.0021, Recall@20: 0.0042, NDCG@20: 0.0033\n",
      "Epoch 399/500, Train Loss: 0.0015, HR@20: 0.0021, Recall@20: 0.0042, NDCG@20: 0.0033\n",
      "Epoch 400/500, Train Loss: 0.0015, HR@20: 0.0021, Recall@20: 0.0042, NDCG@20: 0.0032\n",
      "Epoch 401/500, Train Loss: 0.0014, HR@20: 0.0020, Recall@20: 0.0041, NDCG@20: 0.0032\n",
      "Epoch 402/500, Train Loss: 0.0014, HR@20: 0.0020, Recall@20: 0.0041, NDCG@20: 0.0032\n",
      "Epoch 403/500, Train Loss: 0.0014, HR@20: 0.0020, Recall@20: 0.0041, NDCG@20: 0.0032\n",
      "Epoch 404/500, Train Loss: 0.0014, HR@20: 0.0020, Recall@20: 0.0041, NDCG@20: 0.0031\n",
      "Epoch 405/500, Train Loss: 0.0013, HR@20: 0.0020, Recall@20: 0.0040, NDCG@20: 0.0031\n",
      "Epoch 406/500, Train Loss: 0.0013, HR@20: 0.0020, Recall@20: 0.0040, NDCG@20: 0.0031\n",
      "Epoch 407/500, Train Loss: 0.0013, HR@20: 0.0020, Recall@20: 0.0040, NDCG@20: 0.0031\n",
      "Epoch 408/500, Train Loss: 0.0013, HR@20: 0.0020, Recall@20: 0.0040, NDCG@20: 0.0031\n",
      "Epoch 409/500, Train Loss: 0.0013, HR@20: 0.0020, Recall@20: 0.0040, NDCG@20: 0.0031\n",
      "Epoch 410/500, Train Loss: 0.0012, HR@20: 0.0020, Recall@20: 0.0039, NDCG@20: 0.0031\n",
      "Epoch 411/500, Train Loss: 0.0012, HR@20: 0.0019, Recall@20: 0.0039, NDCG@20: 0.0031\n",
      "Epoch 412/500, Train Loss: 0.0012, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0030\n",
      "Epoch 413/500, Train Loss: 0.0012, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0030\n",
      "Epoch 414/500, Train Loss: 0.0012, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0030\n",
      "Epoch 415/500, Train Loss: 0.0012, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0030\n",
      "Epoch 416/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0030\n",
      "Epoch 417/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 418/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 419/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 420/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 421/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 422/500, Train Loss: 0.0011, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 423/500, Train Loss: 0.0010, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 424/500, Train Loss: 0.0010, HR@20: 0.0019, Recall@20: 0.0038, NDCG@20: 0.0029\n",
      "Epoch 425/500, Train Loss: 0.0010, HR@20: 0.0019, Recall@20: 0.0037, NDCG@20: 0.0029\n",
      "Epoch 426/500, Train Loss: 0.0010, HR@20: 0.0019, Recall@20: 0.0037, NDCG@20: 0.0029\n",
      "Epoch 427/500, Train Loss: 0.0010, HR@20: 0.0019, Recall@20: 0.0037, NDCG@20: 0.0029\n",
      "Epoch 428/500, Train Loss: 0.0010, HR@20: 0.0018, Recall@20: 0.0037, NDCG@20: 0.0029\n",
      "Epoch 429/500, Train Loss: 0.0010, HR@20: 0.0018, Recall@20: 0.0037, NDCG@20: 0.0029\n",
      "Epoch 430/500, Train Loss: 0.0010, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 431/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 432/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 433/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 434/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 435/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 436/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0036, NDCG@20: 0.0028\n",
      "Epoch 437/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 438/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 439/500, Train Loss: 0.0009, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 440/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 441/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 442/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 443/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 444/500, Train Loss: 0.0008, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 445/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 446/500, Train Loss: 0.0008, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 447/500, Train Loss: 0.0008, HR@20: 0.0018, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 448/500, Train Loss: 0.0008, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0027\n",
      "Epoch 449/500, Train Loss: 0.0008, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0026\n",
      "Epoch 450/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 451/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0026\n",
      "Epoch 452/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 453/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 454/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 455/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 456/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 457/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0026\n",
      "Epoch 458/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0035, NDCG@20: 0.0026\n",
      "Epoch 459/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 460/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 461/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 462/500, Train Loss: 0.0007, HR@20: 0.0017, Recall@20: 0.0034, NDCG@20: 0.0026\n",
      "Epoch 463/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 464/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 465/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 466/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 467/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 468/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 469/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 470/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 471/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 472/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 473/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 474/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 475/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 476/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 477/500, Train Loss: 0.0006, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 478/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 479/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 480/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 481/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 482/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 483/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 484/500, Train Loss: 0.0005, HR@20: 0.0016, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 485/500, Train Loss: 0.0005, HR@20: 0.0016, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 486/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 487/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 488/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 489/500, Train Loss: 0.0005, HR@20: 0.0016, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 490/500, Train Loss: 0.0005, HR@20: 0.0016, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 491/500, Train Loss: 0.0005, HR@20: 0.0016, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 492/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 493/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 494/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0032, NDCG@20: 0.0025\n",
      "Epoch 495/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 496/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 497/500, Train Loss: 0.0005, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0025\n",
      "Epoch 498/500, Train Loss: 0.0004, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 499/500, Train Loss: 0.0004, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Epoch 500/500, Train Loss: 0.0004, HR@20: 0.0017, Recall@20: 0.0033, NDCG@20: 0.0026\n",
      "Total time: 7955.08s\n"
     ]
    }
   ],
   "source": [
    "config['epochs'] = 500\n",
    "retrain_model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "retrain_model, recall, ndcg = MF_based_eva(retrain_model, config, retain_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f21b370cdef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0008, Recall@20: 0.0036, NDCG@20: 0.0018\n"
     ]
    }
   ],
   "source": [
    "MF_forget_data_eva(retrain_model, None, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5043dce93944734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['epochs'] = 100\n",
    "# Define the model\n",
    "teacher = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "student = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "\n",
    "# Load the model\n",
    "teacher.load_state_dict(torch.load(f\"MF_Yelp2018_{config['epochs']}_Epochs_Top_{config['k']}.pt\"))\n",
    "student.load_state_dict(torch.load(f\"MF_Yelp2018_{config['epochs']}_Epochs_Top_{config['k']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e81b165fcc06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\.conda\\envs\\master\\lib\\site-packages\\torch_geometric\\data\\storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_label_index', 'x', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6953, HR@20: 0.0109, Recall@20: 0.0214, NDCG@20: 0.0183\n",
      "Epoch 2/50, Train Loss: 0.6953, HR@20: 0.0109, Recall@20: 0.0214, NDCG@20: 0.0183\n",
      "Epoch 3/50, Train Loss: 0.6953, HR@20: 0.0109, Recall@20: 0.0214, NDCG@20: 0.0183\n",
      "Epoch 4/50, Train Loss: 0.6953, HR@20: 0.0109, Recall@20: 0.0214, NDCG@20: 0.0183\n",
      "Epoch 5/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 6/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 7/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 8/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 9/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 10/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 11/50, Train Loss: 0.6952, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 12/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 13/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 14/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 15/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 16/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 17/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 18/50, Train Loss: 0.6951, HR@20: 0.0109, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 19/50, Train Loss: 0.6951, HR@20: 0.0108, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 20/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 21/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0213, NDCG@20: 0.0182\n",
      "Epoch 22/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 23/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 24/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 25/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 26/50, Train Loss: 0.6950, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 27/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0182\n",
      "Epoch 28/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 29/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 30/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 31/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 32/50, Train Loss: 0.6949, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 33/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 34/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 35/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 36/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0212, NDCG@20: 0.0181\n",
      "Epoch 37/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 38/50, Train Loss: 0.6948, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 39/50, Train Loss: 0.6947, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 40/50, Train Loss: 0.6947, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 41/50, Train Loss: 0.6947, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 42/50, Train Loss: 0.6947, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 43/50, Train Loss: 0.6947, HR@20: 0.0108, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 44/50, Train Loss: 0.6947, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 45/50, Train Loss: 0.6947, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 46/50, Train Loss: 0.6946, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 47/50, Train Loss: 0.6946, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 48/50, Train Loss: 0.6946, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 49/50, Train Loss: 0.6946, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Epoch 50/50, Train Loss: 0.6946, HR@20: 0.0107, Recall@20: 0.0211, NDCG@20: 0.0181\n",
      "Running time: 734.81s\n"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['beta'] = 0.7\n",
    "config['alpha'] = 0.3\n",
    "config['epochs'] = 50\n",
    "config['gamma'] = 1e-6 # contrastive loss\n",
    "config['delta'] = 1e-3 # regularization loss\n",
    "config['tuning_type'] = 'gpf'\n",
    "config['weight_decay'] = 0.001\n",
    "config['regularization'] = False\n",
    "config['Contrastive_loss'] = False\n",
    "student, prompt= prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af099af75240b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0059, Recall@20: 0.0287, NDCG@20: 0.0163\n"
     ]
    }
   ],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626b2b9c8eb086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = False\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efd81dffe87680",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0922f94ec8f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0210, NDCG@20: 0.0173\n",
      "Epoch 2/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0210, NDCG@20: 0.0172\n",
      "Epoch 3/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0209, NDCG@20: 0.0172\n",
      "Epoch 4/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0209, NDCG@20: 0.0172\n",
      "Epoch 5/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0209, NDCG@20: 0.0172\n",
      "Epoch 6/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0209, NDCG@20: 0.0172\n",
      "Epoch 7/50, Train Loss: 0.6969, HR@20: 0.0105, Recall@20: 0.0209, NDCG@20: 0.0172\n",
      "Epoch 8/50, Train Loss: 0.6969, HR@20: 0.0104, Recall@20: 0.0208, NDCG@20: 0.0171\n",
      "Epoch 9/50, Train Loss: 0.6969, HR@20: 0.0104, Recall@20: 0.0208, NDCG@20: 0.0171\n",
      "Epoch 10/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0208, NDCG@20: 0.0171\n",
      "Epoch 11/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0171\n",
      "Epoch 12/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0171\n",
      "Epoch 13/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0171\n",
      "Epoch 14/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0170\n",
      "Epoch 15/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0170\n",
      "Epoch 16/50, Train Loss: 0.6968, HR@20: 0.0104, Recall@20: 0.0207, NDCG@20: 0.0170\n",
      "Epoch 17/50, Train Loss: 0.6968, HR@20: 0.0103, Recall@20: 0.0206, NDCG@20: 0.0170\n",
      "Epoch 18/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0206, NDCG@20: 0.0170\n",
      "Epoch 19/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0206, NDCG@20: 0.0170\n",
      "Epoch 20/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0206, NDCG@20: 0.0169\n",
      "Epoch 21/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0205, NDCG@20: 0.0169\n",
      "Epoch 22/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0205, NDCG@20: 0.0169\n",
      "Epoch 23/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0205, NDCG@20: 0.0169\n",
      "Epoch 24/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0205, NDCG@20: 0.0169\n",
      "Epoch 25/50, Train Loss: 0.6967, HR@20: 0.0103, Recall@20: 0.0205, NDCG@20: 0.0169\n",
      "Epoch 26/50, Train Loss: 0.6966, HR@20: 0.0103, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 27/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 28/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 29/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 30/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 31/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0204, NDCG@20: 0.0168\n",
      "Epoch 32/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0203, NDCG@20: 0.0167\n",
      "Epoch 33/50, Train Loss: 0.6966, HR@20: 0.0102, Recall@20: 0.0203, NDCG@20: 0.0167\n",
      "Epoch 34/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0203, NDCG@20: 0.0167\n",
      "Epoch 35/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0203, NDCG@20: 0.0167\n",
      "Epoch 36/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0202, NDCG@20: 0.0167\n",
      "Epoch 37/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0202, NDCG@20: 0.0167\n",
      "Epoch 38/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0202, NDCG@20: 0.0166\n",
      "Epoch 39/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0202, NDCG@20: 0.0166\n",
      "Epoch 40/50, Train Loss: 0.6965, HR@20: 0.0102, Recall@20: 0.0202, NDCG@20: 0.0166\n",
      "Epoch 41/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0202, NDCG@20: 0.0166\n",
      "Epoch 42/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0201, NDCG@20: 0.0166\n",
      "Epoch 43/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0201, NDCG@20: 0.0166\n",
      "Epoch 44/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0201, NDCG@20: 0.0165\n",
      "Epoch 45/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0201, NDCG@20: 0.0165\n",
      "Epoch 46/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0200, NDCG@20: 0.0165\n",
      "Epoch 47/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0200, NDCG@20: 0.0165\n",
      "Epoch 48/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0200, NDCG@20: 0.0165\n",
      "Epoch 49/50, Train Loss: 0.6964, HR@20: 0.0101, Recall@20: 0.0200, NDCG@20: 0.0165\n",
      "Epoch 50/50, Train Loss: 0.6963, HR@20: 0.0101, Recall@20: 0.0200, NDCG@20: 0.0164\n",
      "Running time: 642.06s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrastive_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m student, prompt, epoch_tracks, test_topks \u001b[38;5;241m=\u001b[39m prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = False\n",
    "\n",
    "student, prompt= prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7a286bb333ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c6b31dbe755d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1627fc3fb34dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8517d3583069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuning_type'] = 'gpf-plus'\n",
    "config[\"number_p\"] = 10 # The number of prompts\n",
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd69e5003a4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
