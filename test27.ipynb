{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.BPRMF import *\n",
    "from preprocess.Yelp import *\n",
    "from evaluation.BPRMF_SISA import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/yelp2018'\n",
    "dataset = Yelp(path)\n",
    "\n",
    "# Data(num_nodes=144242, edge_index=[2, 2380730], edge_label_index=[2, 603378])\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'lr':0.001,\n",
    "    'epochs': 100,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None\n",
    "}\n",
    "model = BPRMF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config['epochs'] = 500\n",
    "config['num_shards'] = 5\n",
    "model_list =[]\n",
    "\n",
    "for _ in range(config['num_shards']):\n",
    "    model_list.append(BPRMF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device))\n",
    "\n",
    "shard_models, shards, epoch_tracks, test_topks = sisa_BPRMF_eva(model_list, config, data, device)"
   ],
   "id": "5c1396e363229140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Basic setting\n",
    "num_edges = data.edge_index.size(1)\n",
    "perm = torch.randperm(num_edges)\n",
    "split = int(num_edges * 0.1)  # 10% of edges will be retained\n",
    "\n",
    "# Define the data for forget and retain dataset\n",
    "forget_data = Data()\n",
    "retain_data = Data()\n",
    "\n",
    "forget_data.num_nodes = data.num_nodes\n",
    "retain_data.num_nodes = data.num_nodes\n",
    "forget_data.edge_index = data.edge_index[:, perm[:split]]\n",
    "retain_data.edge_index = data.edge_index[:, perm[split:]]\n",
    "forget_data.edge_label_index = data.edge_label_index\n",
    "retain_data.edge_label_index = data.edge_label_index"
   ],
   "id": "bd0fbd767edebcd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shard_models = sisa_BPRMF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)",
   "id": "2205e3ded0f4d167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sisa_BPRMF_forget_data_eva(shard_models, forget_data, config, device)",
   "id": "a8f5b3eda2182823"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
