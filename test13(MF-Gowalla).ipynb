{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.MF import *\n",
    "from preprocess.Gowalla import *\n",
    "from evaluation.MF_evaluation import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/Gowalla'\n",
    "dataset = Gowalla(path)\n",
    "\n",
    "# Data(num_nodes=144242, edge_index=[2, 2380730], edge_label_index=[2, 603378])\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'learning_rate': 1e-5,  # over-fitting\n",
    "    'epochs': 100,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    'global_bias':(data.edge_index.size(1) + data.edge_label_index.size(1) + 2) / (num_books * num_users)\n",
    "}\n",
    "model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7cff3d485699f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.9978, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0003\n",
      "Epoch 2/100, Train Loss: 0.9957, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0003\n",
      "Epoch 3/100, Train Loss: 0.9936, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0003\n",
      "Epoch 4/100, Train Loss: 0.9915, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0003\n",
      "Epoch 5/100, Train Loss: 0.9894, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0003\n",
      "Epoch 6/100, Train Loss: 0.9873, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 7/100, Train Loss: 0.9852, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 8/100, Train Loss: 0.9831, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 9/100, Train Loss: 0.9810, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 10/100, Train Loss: 0.9790, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 11/100, Train Loss: 0.9769, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 12/100, Train Loss: 0.9748, HR@20: 0.0002, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 13/100, Train Loss: 0.9727, HR@20: 0.0002, Recall@20: 0.0007, NDCG@20: 0.0004\n",
      "Epoch 14/100, Train Loss: 0.9707, HR@20: 0.0002, Recall@20: 0.0007, NDCG@20: 0.0004\n",
      "Epoch 15/100, Train Loss: 0.9686, HR@20: 0.0002, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 16/100, Train Loss: 0.9665, HR@20: 0.0002, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 17/100, Train Loss: 0.9645, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 18/100, Train Loss: 0.9624, HR@20: 0.0003, Recall@20: 0.0008, NDCG@20: 0.0005\n",
      "Epoch 19/100, Train Loss: 0.9603, HR@20: 0.0003, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 20/100, Train Loss: 0.9583, HR@20: 0.0003, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 21/100, Train Loss: 0.9562, HR@20: 0.0003, Recall@20: 0.0009, NDCG@20: 0.0006\n",
      "Epoch 22/100, Train Loss: 0.9541, HR@20: 0.0004, Recall@20: 0.0010, NDCG@20: 0.0007\n",
      "Epoch 23/100, Train Loss: 0.9521, HR@20: 0.0004, Recall@20: 0.0011, NDCG@20: 0.0008\n",
      "Epoch 24/100, Train Loss: 0.9500, HR@20: 0.0005, Recall@20: 0.0012, NDCG@20: 0.0009\n",
      "Epoch 25/100, Train Loss: 0.9480, HR@20: 0.0005, Recall@20: 0.0013, NDCG@20: 0.0010\n",
      "Epoch 26/100, Train Loss: 0.9459, HR@20: 0.0006, Recall@20: 0.0015, NDCG@20: 0.0011\n",
      "Epoch 27/100, Train Loss: 0.9438, HR@20: 0.0007, Recall@20: 0.0016, NDCG@20: 0.0013\n",
      "Epoch 28/100, Train Loss: 0.9417, HR@20: 0.0008, Recall@20: 0.0018, NDCG@20: 0.0015\n",
      "Epoch 29/100, Train Loss: 0.9397, HR@20: 0.0009, Recall@20: 0.0021, NDCG@20: 0.0018\n",
      "Epoch 30/100, Train Loss: 0.9376, HR@20: 0.0012, Recall@20: 0.0025, NDCG@20: 0.0022\n",
      "Epoch 31/100, Train Loss: 0.9355, HR@20: 0.0014, Recall@20: 0.0029, NDCG@20: 0.0027\n",
      "Epoch 32/100, Train Loss: 0.9334, HR@20: 0.0017, Recall@20: 0.0036, NDCG@20: 0.0033\n",
      "Epoch 33/100, Train Loss: 0.9313, HR@20: 0.0021, Recall@20: 0.0043, NDCG@20: 0.0041\n",
      "Epoch 34/100, Train Loss: 0.9292, HR@20: 0.0025, Recall@20: 0.0052, NDCG@20: 0.0048\n",
      "Epoch 35/100, Train Loss: 0.9271, HR@20: 0.0030, Recall@20: 0.0061, NDCG@20: 0.0058\n",
      "Epoch 36/100, Train Loss: 0.9250, HR@20: 0.0036, Recall@20: 0.0072, NDCG@20: 0.0069\n",
      "Epoch 37/100, Train Loss: 0.9228, HR@20: 0.0041, Recall@20: 0.0083, NDCG@20: 0.0080\n",
      "Epoch 38/100, Train Loss: 0.9207, HR@20: 0.0047, Recall@20: 0.0095, NDCG@20: 0.0092\n",
      "Epoch 39/100, Train Loss: 0.9185, HR@20: 0.0053, Recall@20: 0.0110, NDCG@20: 0.0105\n",
      "Epoch 40/100, Train Loss: 0.9164, HR@20: 0.0061, Recall@20: 0.0125, NDCG@20: 0.0120\n",
      "Epoch 41/100, Train Loss: 0.9142, HR@20: 0.0067, Recall@20: 0.0142, NDCG@20: 0.0135\n",
      "Epoch 42/100, Train Loss: 0.9120, HR@20: 0.0074, Recall@20: 0.0157, NDCG@20: 0.0150\n",
      "Epoch 43/100, Train Loss: 0.9097, HR@20: 0.0081, Recall@20: 0.0175, NDCG@20: 0.0166\n",
      "Epoch 44/100, Train Loss: 0.9075, HR@20: 0.0089, Recall@20: 0.0194, NDCG@20: 0.0181\n",
      "Epoch 45/100, Train Loss: 0.9053, HR@20: 0.0096, Recall@20: 0.0211, NDCG@20: 0.0197\n",
      "Epoch 46/100, Train Loss: 0.9030, HR@20: 0.0103, Recall@20: 0.0230, NDCG@20: 0.0214\n",
      "Epoch 47/100, Train Loss: 0.9007, HR@20: 0.0110, Recall@20: 0.0250, NDCG@20: 0.0230\n",
      "Epoch 48/100, Train Loss: 0.8984, HR@20: 0.0117, Recall@20: 0.0268, NDCG@20: 0.0247\n",
      "Epoch 49/100, Train Loss: 0.8960, HR@20: 0.0124, Recall@20: 0.0288, NDCG@20: 0.0264\n",
      "Epoch 50/100, Train Loss: 0.8937, HR@20: 0.0131, Recall@20: 0.0305, NDCG@20: 0.0280\n",
      "Epoch 51/100, Train Loss: 0.8913, HR@20: 0.0137, Recall@20: 0.0327, NDCG@20: 0.0296\n",
      "Epoch 52/100, Train Loss: 0.8889, HR@20: 0.0143, Recall@20: 0.0345, NDCG@20: 0.0312\n",
      "Epoch 53/100, Train Loss: 0.8864, HR@20: 0.0150, Recall@20: 0.0364, NDCG@20: 0.0328\n",
      "Epoch 54/100, Train Loss: 0.8839, HR@20: 0.0155, Recall@20: 0.0382, NDCG@20: 0.0342\n",
      "Epoch 55/100, Train Loss: 0.8814, HR@20: 0.0162, Recall@20: 0.0403, NDCG@20: 0.0359\n",
      "Epoch 56/100, Train Loss: 0.8789, HR@20: 0.0167, Recall@20: 0.0421, NDCG@20: 0.0372\n",
      "Epoch 57/100, Train Loss: 0.8763, HR@20: 0.0173, Recall@20: 0.0440, NDCG@20: 0.0388\n",
      "Epoch 58/100, Train Loss: 0.8737, HR@20: 0.0178, Recall@20: 0.0458, NDCG@20: 0.0402\n",
      "Epoch 59/100, Train Loss: 0.8711, HR@20: 0.0182, Recall@20: 0.0473, NDCG@20: 0.0414\n",
      "Epoch 60/100, Train Loss: 0.8685, HR@20: 0.0187, Recall@20: 0.0492, NDCG@20: 0.0429\n",
      "Epoch 61/100, Train Loss: 0.8658, HR@20: 0.0191, Recall@20: 0.0507, NDCG@20: 0.0441\n",
      "Epoch 62/100, Train Loss: 0.8631, HR@20: 0.0196, Recall@20: 0.0525, NDCG@20: 0.0454\n",
      "Epoch 63/100, Train Loss: 0.8603, HR@20: 0.0200, Recall@20: 0.0539, NDCG@20: 0.0466\n",
      "Epoch 64/100, Train Loss: 0.8575, HR@20: 0.0204, Recall@20: 0.0553, NDCG@20: 0.0477\n",
      "Epoch 65/100, Train Loss: 0.8547, HR@20: 0.0207, Recall@20: 0.0567, NDCG@20: 0.0488\n",
      "Epoch 66/100, Train Loss: 0.8519, HR@20: 0.0210, Recall@20: 0.0580, NDCG@20: 0.0498\n",
      "Epoch 67/100, Train Loss: 0.8490, HR@20: 0.0213, Recall@20: 0.0591, NDCG@20: 0.0507\n",
      "Epoch 68/100, Train Loss: 0.8461, HR@20: 0.0216, Recall@20: 0.0604, NDCG@20: 0.0517\n",
      "Epoch 69/100, Train Loss: 0.8431, HR@20: 0.0219, Recall@20: 0.0615, NDCG@20: 0.0526\n",
      "Epoch 70/100, Train Loss: 0.8401, HR@20: 0.0222, Recall@20: 0.0625, NDCG@20: 0.0535\n",
      "Epoch 71/100, Train Loss: 0.8371, HR@20: 0.0224, Recall@20: 0.0635, NDCG@20: 0.0543\n",
      "Epoch 72/100, Train Loss: 0.8340, HR@20: 0.0226, Recall@20: 0.0644, NDCG@20: 0.0551\n",
      "Epoch 73/100, Train Loss: 0.8310, HR@20: 0.0228, Recall@20: 0.0654, NDCG@20: 0.0558\n",
      "Epoch 74/100, Train Loss: 0.8278, HR@20: 0.0230, Recall@20: 0.0664, NDCG@20: 0.0565\n",
      "Epoch 75/100, Train Loss: 0.8247, HR@20: 0.0232, Recall@20: 0.0673, NDCG@20: 0.0573\n",
      "Epoch 76/100, Train Loss: 0.8215, HR@20: 0.0234, Recall@20: 0.0681, NDCG@20: 0.0580\n",
      "Epoch 77/100, Train Loss: 0.8183, HR@20: 0.0236, Recall@20: 0.0688, NDCG@20: 0.0586\n",
      "Epoch 78/100, Train Loss: 0.8150, HR@20: 0.0238, Recall@20: 0.0696, NDCG@20: 0.0592\n",
      "Epoch 79/100, Train Loss: 0.8117, HR@20: 0.0239, Recall@20: 0.0702, NDCG@20: 0.0598\n",
      "Epoch 80/100, Train Loss: 0.8084, HR@20: 0.0241, Recall@20: 0.0709, NDCG@20: 0.0604\n",
      "Epoch 81/100, Train Loss: 0.8051, HR@20: 0.0242, Recall@20: 0.0716, NDCG@20: 0.0610\n",
      "Epoch 82/100, Train Loss: 0.8017, HR@20: 0.0243, Recall@20: 0.0720, NDCG@20: 0.0615\n",
      "Epoch 83/100, Train Loss: 0.7983, HR@20: 0.0245, Recall@20: 0.0727, NDCG@20: 0.0620\n",
      "Epoch 84/100, Train Loss: 0.7948, HR@20: 0.0246, Recall@20: 0.0733, NDCG@20: 0.0625\n",
      "Epoch 85/100, Train Loss: 0.7914, HR@20: 0.0247, Recall@20: 0.0737, NDCG@20: 0.0629\n",
      "Epoch 86/100, Train Loss: 0.7879, HR@20: 0.0248, Recall@20: 0.0742, NDCG@20: 0.0634\n",
      "Epoch 87/100, Train Loss: 0.7843, HR@20: 0.0249, Recall@20: 0.0748, NDCG@20: 0.0637\n",
      "Epoch 88/100, Train Loss: 0.7808, HR@20: 0.0250, Recall@20: 0.0752, NDCG@20: 0.0641\n",
      "Epoch 89/100, Train Loss: 0.7772, HR@20: 0.0251, Recall@20: 0.0758, NDCG@20: 0.0646\n",
      "Epoch 90/100, Train Loss: 0.7735, HR@20: 0.0252, Recall@20: 0.0763, NDCG@20: 0.0650\n",
      "Epoch 91/100, Train Loss: 0.7699, HR@20: 0.0254, Recall@20: 0.0770, NDCG@20: 0.0655\n",
      "Epoch 92/100, Train Loss: 0.7662, HR@20: 0.0255, Recall@20: 0.0773, NDCG@20: 0.0659\n",
      "Epoch 93/100, Train Loss: 0.7625, HR@20: 0.0255, Recall@20: 0.0775, NDCG@20: 0.0661\n",
      "Epoch 94/100, Train Loss: 0.7587, HR@20: 0.0255, Recall@20: 0.0778, NDCG@20: 0.0664\n",
      "Epoch 95/100, Train Loss: 0.7550, HR@20: 0.0256, Recall@20: 0.0781, NDCG@20: 0.0667\n",
      "Epoch 96/100, Train Loss: 0.7512, HR@20: 0.0257, Recall@20: 0.0784, NDCG@20: 0.0669\n",
      "Epoch 97/100, Train Loss: 0.7474, HR@20: 0.0257, Recall@20: 0.0788, NDCG@20: 0.0672\n",
      "Epoch 98/100, Train Loss: 0.7435, HR@20: 0.0258, Recall@20: 0.0791, NDCG@20: 0.0675\n",
      "Epoch 99/100, Train Loss: 0.7396, HR@20: 0.0258, Recall@20: 0.0794, NDCG@20: 0.0678\n",
      "Epoch 100/100, Train Loss: 0.7357, HR@20: 0.0260, Recall@20: 0.0799, NDCG@20: 0.0682\n",
      "Total time: 1442.61s\n"
     ]
    }
   ],
   "source": [
    "model, recall, ndcg = MF_based_eva(model, config, data, device)\n",
    "# Store the model parameters\n",
    "torch.save(model.state_dict(), f\"MF_Gowalla_{config['epochs']}_Epochs_Top_{config['k']}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
