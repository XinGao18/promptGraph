{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.MF import *\n",
    "from preprocess.AmazonBook import *\n",
    "from evaluation.MF_evaluation import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/amazon-book'\n",
    "dataset = AmazonBook(path)\n",
    "\n",
    "# Data(num_nodes=144242, edge_index=[2, 2380730], edge_label_index=[2, 603378])\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'learning_rate': 1e-5,  # over-fitting\n",
    "    'epochs': 120,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    'global_bias':(data.edge_index.size(1) + data.edge_label_index.size(1) + 2) / (num_books * num_users)\n",
    "}\n",
    "model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634988892bcb9cb4",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b389a9fb3cd1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setting\n",
    "num_edges = data.edge_index.size(1)\n",
    "perm = torch.randperm(num_edges)\n",
    "split = int(num_edges * 0.1)  # 10% of edges will be retained\n",
    "\n",
    "# Define the data for forget and retain dataset\n",
    "forget_data = Data()\n",
    "retain_data = Data()\n",
    "\n",
    "forget_data.num_nodes = data.num_nodes\n",
    "retain_data.num_nodes = data.num_nodes\n",
    "forget_data.edge_index = data.edge_index[:, perm[:split]]\n",
    "retain_data.edge_index = data.edge_index[:, perm[split:]]\n",
    "forget_data.edge_label_index = data.edge_label_index\n",
    "retain_data.edge_label_index = data.edge_label_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb32cb8fa1e44c",
   "metadata": {},
   "source": [
    "# Retain MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdc41180c6f6b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Train Loss: 0.9967, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 2/120, Train Loss: 0.9924, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 3/120, Train Loss: 0.9880, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 4/120, Train Loss: 0.9837, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 5/120, Train Loss: 0.9794, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 6/120, Train Loss: 0.9750, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 7/120, Train Loss: 0.9707, HR@20: 0.0001, Recall@20: 0.0002, NDCG@20: 0.0002\n",
      "Epoch 8/120, Train Loss: 0.9664, HR@20: 0.0001, Recall@20: 0.0003, NDCG@20: 0.0002\n",
      "Epoch 9/120, Train Loss: 0.9621, HR@20: 0.0002, Recall@20: 0.0003, NDCG@20: 0.0002\n",
      "Epoch 10/120, Train Loss: 0.9578, HR@20: 0.0002, Recall@20: 0.0003, NDCG@20: 0.0003\n",
      "Epoch 11/120, Train Loss: 0.9536, HR@20: 0.0002, Recall@20: 0.0004, NDCG@20: 0.0004\n",
      "Epoch 12/120, Train Loss: 0.9493, HR@20: 0.0004, Recall@20: 0.0006, NDCG@20: 0.0006\n",
      "Epoch 13/120, Train Loss: 0.9450, HR@20: 0.0006, Recall@20: 0.0010, NDCG@20: 0.0009\n",
      "Epoch 14/120, Train Loss: 0.9407, HR@20: 0.0009, Recall@20: 0.0015, NDCG@20: 0.0014\n",
      "Epoch 15/120, Train Loss: 0.9364, HR@20: 0.0013, Recall@20: 0.0022, NDCG@20: 0.0020\n",
      "Epoch 16/120, Train Loss: 0.9320, HR@20: 0.0017, Recall@20: 0.0029, NDCG@20: 0.0027\n",
      "Epoch 17/120, Train Loss: 0.9276, HR@20: 0.0021, Recall@20: 0.0036, NDCG@20: 0.0034\n",
      "Epoch 18/120, Train Loss: 0.9232, HR@20: 0.0025, Recall@20: 0.0044, NDCG@20: 0.0041\n",
      "Epoch 19/120, Train Loss: 0.9187, HR@20: 0.0030, Recall@20: 0.0053, NDCG@20: 0.0047\n",
      "Epoch 20/120, Train Loss: 0.9142, HR@20: 0.0033, Recall@20: 0.0060, NDCG@20: 0.0053\n",
      "Epoch 21/120, Train Loss: 0.9095, HR@20: 0.0036, Recall@20: 0.0067, NDCG@20: 0.0058\n",
      "Epoch 22/120, Train Loss: 0.9048, HR@20: 0.0039, Recall@20: 0.0073, NDCG@20: 0.0063\n",
      "Epoch 23/120, Train Loss: 0.9000, HR@20: 0.0041, Recall@20: 0.0079, NDCG@20: 0.0067\n",
      "Epoch 24/120, Train Loss: 0.8951, HR@20: 0.0043, Recall@20: 0.0082, NDCG@20: 0.0069\n",
      "Epoch 25/120, Train Loss: 0.8900, HR@20: 0.0044, Recall@20: 0.0087, NDCG@20: 0.0072\n",
      "Epoch 26/120, Train Loss: 0.8849, HR@20: 0.0045, Recall@20: 0.0089, NDCG@20: 0.0074\n",
      "Epoch 27/120, Train Loss: 0.8795, HR@20: 0.0046, Recall@20: 0.0092, NDCG@20: 0.0076\n",
      "Epoch 28/120, Train Loss: 0.8741, HR@20: 0.0047, Recall@20: 0.0094, NDCG@20: 0.0077\n",
      "Epoch 29/120, Train Loss: 0.8685, HR@20: 0.0048, Recall@20: 0.0096, NDCG@20: 0.0078\n",
      "Epoch 30/120, Train Loss: 0.8628, HR@20: 0.0048, Recall@20: 0.0096, NDCG@20: 0.0079\n",
      "Epoch 31/120, Train Loss: 0.8569, HR@20: 0.0048, Recall@20: 0.0098, NDCG@20: 0.0080\n",
      "Epoch 32/120, Train Loss: 0.8509, HR@20: 0.0049, Recall@20: 0.0099, NDCG@20: 0.0080\n",
      "Epoch 33/120, Train Loss: 0.8447, HR@20: 0.0049, Recall@20: 0.0100, NDCG@20: 0.0081\n",
      "Epoch 34/120, Train Loss: 0.8384, HR@20: 0.0049, Recall@20: 0.0100, NDCG@20: 0.0081\n",
      "Epoch 35/120, Train Loss: 0.8319, HR@20: 0.0049, Recall@20: 0.0101, NDCG@20: 0.0082\n",
      "Epoch 36/120, Train Loss: 0.8253, HR@20: 0.0049, Recall@20: 0.0101, NDCG@20: 0.0082\n",
      "Epoch 37/120, Train Loss: 0.8185, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 38/120, Train Loss: 0.8116, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 39/120, Train Loss: 0.8046, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 40/120, Train Loss: 0.7974, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 41/120, Train Loss: 0.7901, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 42/120, Train Loss: 0.7826, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 43/120, Train Loss: 0.7751, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 44/120, Train Loss: 0.7674, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 45/120, Train Loss: 0.7596, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 46/120, Train Loss: 0.7516, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0082\n",
      "Epoch 47/120, Train Loss: 0.7436, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 48/120, Train Loss: 0.7355, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 49/120, Train Loss: 0.7272, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 50/120, Train Loss: 0.7189, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 51/120, Train Loss: 0.7104, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 52/120, Train Loss: 0.7019, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 53/120, Train Loss: 0.6933, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 54/120, Train Loss: 0.6846, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 55/120, Train Loss: 0.6758, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 56/120, Train Loss: 0.6670, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 57/120, Train Loss: 0.6581, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 58/120, Train Loss: 0.6491, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 59/120, Train Loss: 0.6401, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 60/120, Train Loss: 0.6310, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 61/120, Train Loss: 0.6219, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 62/120, Train Loss: 0.6128, HR@20: 0.0049, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 63/120, Train Loss: 0.6036, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 64/120, Train Loss: 0.5944, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 65/120, Train Loss: 0.5851, HR@20: 0.0050, Recall@20: 0.0102, NDCG@20: 0.0083\n",
      "Epoch 66/120, Train Loss: 0.5759, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 67/120, Train Loss: 0.5666, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 68/120, Train Loss: 0.5573, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 69/120, Train Loss: 0.5481, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 70/120, Train Loss: 0.5388, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0083\n",
      "Epoch 71/120, Train Loss: 0.5296, HR@20: 0.0050, Recall@20: 0.0103, NDCG@20: 0.0084\n",
      "Epoch 72/120, Train Loss: 0.5203, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0084\n",
      "Epoch 73/120, Train Loss: 0.5111, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0084\n",
      "Epoch 74/120, Train Loss: 0.5020, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0084\n",
      "Epoch 75/120, Train Loss: 0.4928, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0084\n",
      "Epoch 76/120, Train Loss: 0.4837, HR@20: 0.0050, Recall@20: 0.0104, NDCG@20: 0.0084\n",
      "Epoch 77/120, Train Loss: 0.4747, HR@20: 0.0051, Recall@20: 0.0105, NDCG@20: 0.0085\n",
      "Epoch 78/120, Train Loss: 0.4657, HR@20: 0.0051, Recall@20: 0.0105, NDCG@20: 0.0085\n",
      "Epoch 79/120, Train Loss: 0.4568, HR@20: 0.0051, Recall@20: 0.0105, NDCG@20: 0.0085\n",
      "Epoch 80/120, Train Loss: 0.4480, HR@20: 0.0051, Recall@20: 0.0106, NDCG@20: 0.0085\n",
      "Epoch 81/120, Train Loss: 0.4392, HR@20: 0.0051, Recall@20: 0.0106, NDCG@20: 0.0086\n",
      "Epoch 82/120, Train Loss: 0.4305, HR@20: 0.0051, Recall@20: 0.0107, NDCG@20: 0.0086\n",
      "Epoch 83/120, Train Loss: 0.4219, HR@20: 0.0052, Recall@20: 0.0108, NDCG@20: 0.0087\n",
      "Epoch 84/120, Train Loss: 0.4134, HR@20: 0.0052, Recall@20: 0.0109, NDCG@20: 0.0088\n",
      "Epoch 85/120, Train Loss: 0.4050, HR@20: 0.0053, Recall@20: 0.0110, NDCG@20: 0.0089\n",
      "Epoch 86/120, Train Loss: 0.3967, HR@20: 0.0053, Recall@20: 0.0112, NDCG@20: 0.0090\n",
      "Epoch 87/120, Train Loss: 0.3885, HR@20: 0.0054, Recall@20: 0.0112, NDCG@20: 0.0090\n",
      "Epoch 88/120, Train Loss: 0.3804, HR@20: 0.0054, Recall@20: 0.0114, NDCG@20: 0.0091\n",
      "Epoch 89/120, Train Loss: 0.3724, HR@20: 0.0055, Recall@20: 0.0115, NDCG@20: 0.0092\n",
      "Epoch 90/120, Train Loss: 0.3645, HR@20: 0.0055, Recall@20: 0.0117, NDCG@20: 0.0094\n",
      "Epoch 91/120, Train Loss: 0.3568, HR@20: 0.0056, Recall@20: 0.0119, NDCG@20: 0.0095\n",
      "Epoch 92/120, Train Loss: 0.3491, HR@20: 0.0057, Recall@20: 0.0120, NDCG@20: 0.0097\n",
      "Epoch 93/120, Train Loss: 0.3416, HR@20: 0.0058, Recall@20: 0.0122, NDCG@20: 0.0098\n",
      "Epoch 94/120, Train Loss: 0.3342, HR@20: 0.0058, Recall@20: 0.0124, NDCG@20: 0.0100\n",
      "Epoch 95/120, Train Loss: 0.3269, HR@20: 0.0059, Recall@20: 0.0126, NDCG@20: 0.0101\n",
      "Epoch 96/120, Train Loss: 0.3198, HR@20: 0.0060, Recall@20: 0.0128, NDCG@20: 0.0103\n",
      "Epoch 97/120, Train Loss: 0.3128, HR@20: 0.0061, Recall@20: 0.0131, NDCG@20: 0.0106\n",
      "Epoch 98/120, Train Loss: 0.3058, HR@20: 0.0062, Recall@20: 0.0133, NDCG@20: 0.0108\n",
      "Epoch 99/120, Train Loss: 0.2991, HR@20: 0.0063, Recall@20: 0.0135, NDCG@20: 0.0110\n",
      "Epoch 100/120, Train Loss: 0.2924, HR@20: 0.0064, Recall@20: 0.0138, NDCG@20: 0.0113\n",
      "Epoch 101/120, Train Loss: 0.2859, HR@20: 0.0065, Recall@20: 0.0140, NDCG@20: 0.0115\n",
      "Epoch 102/120, Train Loss: 0.2794, HR@20: 0.0066, Recall@20: 0.0142, NDCG@20: 0.0117\n",
      "Epoch 103/120, Train Loss: 0.2731, HR@20: 0.0066, Recall@20: 0.0144, NDCG@20: 0.0118\n",
      "Epoch 104/120, Train Loss: 0.2670, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0119\n",
      "Epoch 105/120, Train Loss: 0.2609, HR@20: 0.0067, Recall@20: 0.0147, NDCG@20: 0.0120\n",
      "Epoch 106/120, Train Loss: 0.2550, HR@20: 0.0068, Recall@20: 0.0149, NDCG@20: 0.0120\n",
      "Epoch 107/120, Train Loss: 0.2491, HR@20: 0.0069, Recall@20: 0.0151, NDCG@20: 0.0122\n",
      "Epoch 108/120, Train Loss: 0.2434, HR@20: 0.0070, Recall@20: 0.0153, NDCG@20: 0.0123\n",
      "Epoch 109/120, Train Loss: 0.2378, HR@20: 0.0070, Recall@20: 0.0155, NDCG@20: 0.0124\n",
      "Epoch 110/120, Train Loss: 0.2323, HR@20: 0.0071, Recall@20: 0.0157, NDCG@20: 0.0125\n",
      "Epoch 111/120, Train Loss: 0.2270, HR@20: 0.0072, Recall@20: 0.0158, NDCG@20: 0.0126\n",
      "Epoch 112/120, Train Loss: 0.2217, HR@20: 0.0072, Recall@20: 0.0159, NDCG@20: 0.0128\n",
      "Epoch 113/120, Train Loss: 0.2165, HR@20: 0.0072, Recall@20: 0.0160, NDCG@20: 0.0128\n",
      "Epoch 114/120, Train Loss: 0.2115, HR@20: 0.0072, Recall@20: 0.0160, NDCG@20: 0.0129\n",
      "Epoch 115/120, Train Loss: 0.2065, HR@20: 0.0072, Recall@20: 0.0160, NDCG@20: 0.0129\n",
      "Epoch 116/120, Train Loss: 0.2017, HR@20: 0.0072, Recall@20: 0.0160, NDCG@20: 0.0129\n",
      "Epoch 117/120, Train Loss: 0.1969, HR@20: 0.0072, Recall@20: 0.0160, NDCG@20: 0.0129\n",
      "Epoch 118/120, Train Loss: 0.1923, HR@20: 0.0071, Recall@20: 0.0159, NDCG@20: 0.0128\n",
      "Epoch 119/120, Train Loss: 0.1878, HR@20: 0.0071, Recall@20: 0.0158, NDCG@20: 0.0127\n",
      "Epoch 120/120, Train Loss: 0.1833, HR@20: 0.0071, Recall@20: 0.0158, NDCG@20: 0.0127\n",
      "Total time: 3977.36s\n"
     ]
    }
   ],
   "source": [
    "config['epochs'] = 120\n",
    "retrain_model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "retrain_model, recall, ndcg = MF_based_eva(retrain_model, config, retain_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54efe4aeb59eed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0044, Recall@20: 0.0241, NDCG@20: 0.0131\n"
     ]
    }
   ],
   "source": [
    "MF_forget_data_eva(retrain_model, None, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1df19ee5ac6f8",
   "metadata": {},
   "source": [
    "# Prompt Unlearning\n",
    "## Case 1: Without Contrastive Loss and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dfc1cc0b7a428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "teacher = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "student = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)\n",
    "\n",
    "# Load the model\n",
    "teacher.load_state_dict(torch.load(f\"MF_Amazon_Book_{config['epochs']}_Epochs_Top_{config['k']}.pt\"))\n",
    "student.load_state_dict(torch.load(f\"MF_Amazon_Book_{config['epochs']}_Epochs_Top_{config['k']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac8daf433abbeddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\.conda\\envs\\master\\lib\\site-packages\\torch_geometric\\data\\storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'x', 'edge_label_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6919, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 2/50, Train Loss: 0.6918, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 3/50, Train Loss: 0.6917, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 4/50, Train Loss: 0.6917, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 5/50, Train Loss: 0.6916, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 6/50, Train Loss: 0.6915, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 7/50, Train Loss: 0.6915, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 8/50, Train Loss: 0.6914, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 9/50, Train Loss: 0.6913, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 10/50, Train Loss: 0.6912, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 11/50, Train Loss: 0.6911, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 12/50, Train Loss: 0.6911, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 13/50, Train Loss: 0.6910, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 14/50, Train Loss: 0.6909, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 15/50, Train Loss: 0.6908, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 16/50, Train Loss: 0.6908, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 17/50, Train Loss: 0.6907, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 18/50, Train Loss: 0.6906, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 19/50, Train Loss: 0.6905, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 20/50, Train Loss: 0.6904, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 21/50, Train Loss: 0.6903, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 22/50, Train Loss: 0.6902, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 23/50, Train Loss: 0.6901, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 24/50, Train Loss: 0.6900, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0085\n",
      "Epoch 25/50, Train Loss: 0.6899, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 26/50, Train Loss: 0.6898, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 27/50, Train Loss: 0.6897, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 28/50, Train Loss: 0.6896, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 29/50, Train Loss: 0.6895, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 30/50, Train Loss: 0.6894, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 31/50, Train Loss: 0.6893, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 32/50, Train Loss: 0.6892, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 33/50, Train Loss: 0.6891, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 34/50, Train Loss: 0.6890, HR@20: 0.0046, Recall@20: 0.0097, NDCG@20: 0.0084\n",
      "Epoch 35/50, Train Loss: 0.6889, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 36/50, Train Loss: 0.6888, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 37/50, Train Loss: 0.6887, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 38/50, Train Loss: 0.6886, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 39/50, Train Loss: 0.6885, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 40/50, Train Loss: 0.6883, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 41/50, Train Loss: 0.6882, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 42/50, Train Loss: 0.6881, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 43/50, Train Loss: 0.6880, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 44/50, Train Loss: 0.6879, HR@20: 0.0046, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 45/50, Train Loss: 0.6877, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 46/50, Train Loss: 0.6876, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 47/50, Train Loss: 0.6875, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 48/50, Train Loss: 0.6874, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 49/50, Train Loss: 0.6873, HR@20: 0.0045, Recall@20: 0.0094, NDCG@20: 0.0082\n",
      "Epoch 50/50, Train Loss: 0.6871, HR@20: 0.0045, Recall@20: 0.0094, NDCG@20: 0.0082\n",
      "Running time: 1539.50s\n"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['beta'] = 0.7\n",
    "config['alpha'] = 0.3\n",
    "config['epochs'] = 50\n",
    "config['gamma'] = 1e-6 # contrastive loss\n",
    "config['delta'] = 1e-3 # regularization loss\n",
    "config['tuning_type'] = 'gpf'\n",
    "config['learning_rate'] = 1e-5\n",
    "config['weight_decay'] = 0\n",
    "config['regularization'] = False\n",
    "config['Contrastive_loss'] = False\n",
    "student, prompt= prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe29f7789ed70158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0025, Recall@20: 0.0132, NDCG@20: 0.0069\n"
     ]
    }
   ],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80933de8348f1574",
   "metadata": {},
   "source": [
    "## Case 2: Without Contrastive Loss but with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4a8844749f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = False\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65724e9e82a7c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cbffdd6cd6341",
   "metadata": {},
   "source": [
    "## Case 3: With Contrastive Loss but without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a2a2e0c60f4a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 3.9762, HR@20: 0.0045, Recall@20: 0.0094, NDCG@20: 0.0083\n",
      "Epoch 2/50, Train Loss: 3.9635, HR@20: 0.0045, Recall@20: 0.0094, NDCG@20: 0.0083\n",
      "Epoch 3/50, Train Loss: 3.9508, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 4/50, Train Loss: 3.9382, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 5/50, Train Loss: 3.9256, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 6/50, Train Loss: 3.9130, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 7/50, Train Loss: 3.9005, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 8/50, Train Loss: 3.8881, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 9/50, Train Loss: 3.8757, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 10/50, Train Loss: 3.8634, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 11/50, Train Loss: 3.8511, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 12/50, Train Loss: 3.8389, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 13/50, Train Loss: 3.8267, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 14/50, Train Loss: 3.8146, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 15/50, Train Loss: 3.8025, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 16/50, Train Loss: 3.7905, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 17/50, Train Loss: 3.7785, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 18/50, Train Loss: 3.7666, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 19/50, Train Loss: 3.7547, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 20/50, Train Loss: 3.7429, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 21/50, Train Loss: 3.7312, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 22/50, Train Loss: 3.7194, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 23/50, Train Loss: 3.7078, HR@20: 0.0045, Recall@20: 0.0095, NDCG@20: 0.0083\n",
      "Epoch 24/50, Train Loss: 3.6962, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 25/50, Train Loss: 3.6846, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 26/50, Train Loss: 3.6731, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 27/50, Train Loss: 3.6616, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 28/50, Train Loss: 3.6502, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 29/50, Train Loss: 3.6388, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 30/50, Train Loss: 3.6275, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 31/50, Train Loss: 3.6162, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 32/50, Train Loss: 3.6050, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 33/50, Train Loss: 3.5938, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 34/50, Train Loss: 3.5827, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 35/50, Train Loss: 3.5716, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 36/50, Train Loss: 3.5605, HR@20: 0.0045, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 37/50, Train Loss: 3.5496, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 38/50, Train Loss: 3.5386, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 39/50, Train Loss: 3.5277, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 40/50, Train Loss: 3.5168, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0083\n",
      "Epoch 41/50, Train Loss: 3.5060, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 42/50, Train Loss: 3.4952, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 43/50, Train Loss: 3.4845, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 44/50, Train Loss: 3.4738, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 45/50, Train Loss: 3.4632, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 46/50, Train Loss: 3.4526, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 47/50, Train Loss: 3.4420, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 48/50, Train Loss: 3.4315, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 49/50, Train Loss: 3.4211, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Epoch 50/50, Train Loss: 3.4106, HR@20: 0.0046, Recall@20: 0.0096, NDCG@20: 0.0084\n",
      "Running time: 1482.86s\n"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['Contrastive_loss'] = True\n",
    "config['regularization'] = False\n",
    "config['gamma'] = 1e-5\n",
    "\n",
    "student, prompt= prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58499388bfedb1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0030, Recall@20: 0.0151, NDCG@20: 0.0086\n"
     ]
    }
   ],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a0c194d7356ae",
   "metadata": {},
   "source": [
    "## Case 4: With Contrastive Loss and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9271a32dcce982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfecd17bae943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ad7d1a48fae8e",
   "metadata": {},
   "source": [
    "# Additional Materials(Multiple Prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce02988806d452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6037, HR@20: 0.0068, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 2/50, Train Loss: 0.6037, HR@20: 0.0068, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 3/50, Train Loss: 0.6037, HR@20: 0.0068, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 4/50, Train Loss: 0.6037, HR@20: 0.0067, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 5/50, Train Loss: 0.6037, HR@20: 0.0067, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 6/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0147, NDCG@20: 0.0123\n",
      "Epoch 7/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 8/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 9/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 10/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 11/50, Train Loss: 0.6036, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 12/50, Train Loss: 0.6035, HR@20: 0.0067, Recall@20: 0.0146, NDCG@20: 0.0123\n",
      "Epoch 13/50, Train Loss: 0.6035, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 14/50, Train Loss: 0.6035, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 15/50, Train Loss: 0.6035, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 16/50, Train Loss: 0.6035, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 17/50, Train Loss: 0.6034, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 18/50, Train Loss: 0.6034, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 19/50, Train Loss: 0.6034, HR@20: 0.0067, Recall@20: 0.0145, NDCG@20: 0.0122\n",
      "Epoch 20/50, Train Loss: 0.6034, HR@20: 0.0067, Recall@20: 0.0144, NDCG@20: 0.0122\n",
      "Epoch 21/50, Train Loss: 0.6034, HR@20: 0.0066, Recall@20: 0.0144, NDCG@20: 0.0122\n",
      "Epoch 22/50, Train Loss: 0.6033, HR@20: 0.0066, Recall@20: 0.0144, NDCG@20: 0.0122\n",
      "Epoch 23/50, Train Loss: 0.6033, HR@20: 0.0066, Recall@20: 0.0144, NDCG@20: 0.0121\n",
      "Epoch 24/50, Train Loss: 0.6033, HR@20: 0.0066, Recall@20: 0.0144, NDCG@20: 0.0121\n",
      "Epoch 25/50, Train Loss: 0.6033, HR@20: 0.0066, Recall@20: 0.0143, NDCG@20: 0.0121\n",
      "Epoch 26/50, Train Loss: 0.6032, HR@20: 0.0066, Recall@20: 0.0143, NDCG@20: 0.0121\n",
      "Epoch 27/50, Train Loss: 0.6032, HR@20: 0.0066, Recall@20: 0.0143, NDCG@20: 0.0121\n",
      "Epoch 28/50, Train Loss: 0.6032, HR@20: 0.0066, Recall@20: 0.0142, NDCG@20: 0.0121\n",
      "Epoch 29/50, Train Loss: 0.6032, HR@20: 0.0066, Recall@20: 0.0142, NDCG@20: 0.0121\n",
      "Epoch 30/50, Train Loss: 0.6031, HR@20: 0.0066, Recall@20: 0.0142, NDCG@20: 0.0121\n"
     ]
    }
   ],
   "source": [
    "config['tuning_type'] = 'gpf-plus'\n",
    "config[\"number_p\"] = 10 # The number of prompts\n",
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_MF_unlearning_eva(teacher, student, config, retain_data, forget_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7459f0d713297",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_forget_data_eva(student, prompt, forget_data, num_users, config['k'], config['batch_size'], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
