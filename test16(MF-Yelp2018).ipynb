{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.MF import *\n",
    "from preprocess.Yelp import *\n",
    "from evaluation.MF_evaluation import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/yelp2018'\n",
    "dataset = Yelp(path)\n",
    "\n",
    "# Data(num_nodes=144242, edge_index=[2, 2380730], edge_label_index=[2, 603378])\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'learning_rate': 1e-5,  # over-fitting\n",
    "    'epochs': 100,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    'global_bias':(data.edge_index.size(1) + data.edge_label_index.size(1) + 2) / (num_books * num_users)\n",
    "}\n",
    "model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a23018bd6a02794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.9960, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 2/100, Train Loss: 0.9928, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 3/100, Train Loss: 0.9896, HR@20: 0.0002, Recall@20: 0.0004, NDCG@20: 0.0004\n",
      "Epoch 4/100, Train Loss: 0.9865, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 5/100, Train Loss: 0.9834, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 6/100, Train Loss: 0.9803, HR@20: 0.0002, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 7/100, Train Loss: 0.9772, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 8/100, Train Loss: 0.9741, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 9/100, Train Loss: 0.9711, HR@20: 0.0003, Recall@20: 0.0005, NDCG@20: 0.0004\n",
      "Epoch 10/100, Train Loss: 0.9680, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0004\n",
      "Epoch 11/100, Train Loss: 0.9650, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 12/100, Train Loss: 0.9619, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch 13/100, Train Loss: 0.9589, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 14/100, Train Loss: 0.9558, HR@20: 0.0003, Recall@20: 0.0007, NDCG@20: 0.0005\n",
      "Epoch 15/100, Train Loss: 0.9528, HR@20: 0.0004, Recall@20: 0.0007, NDCG@20: 0.0006\n",
      "Epoch 16/100, Train Loss: 0.9498, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0006\n",
      "Epoch 17/100, Train Loss: 0.9468, HR@20: 0.0004, Recall@20: 0.0008, NDCG@20: 0.0007\n",
      "Epoch 18/100, Train Loss: 0.9438, HR@20: 0.0005, Recall@20: 0.0009, NDCG@20: 0.0008\n",
      "Epoch 19/100, Train Loss: 0.9407, HR@20: 0.0005, Recall@20: 0.0010, NDCG@20: 0.0009\n",
      "Epoch 20/100, Train Loss: 0.9377, HR@20: 0.0006, Recall@20: 0.0012, NDCG@20: 0.0010\n",
      "Epoch 21/100, Train Loss: 0.9347, HR@20: 0.0008, Recall@20: 0.0014, NDCG@20: 0.0012\n",
      "Epoch 22/100, Train Loss: 0.9317, HR@20: 0.0010, Recall@20: 0.0017, NDCG@20: 0.0015\n",
      "Epoch 23/100, Train Loss: 0.9286, HR@20: 0.0013, Recall@20: 0.0021, NDCG@20: 0.0019\n",
      "Epoch 24/100, Train Loss: 0.9256, HR@20: 0.0016, Recall@20: 0.0027, NDCG@20: 0.0025\n",
      "Epoch 25/100, Train Loss: 0.9225, HR@20: 0.0021, Recall@20: 0.0035, NDCG@20: 0.0032\n",
      "Epoch 26/100, Train Loss: 0.9195, HR@20: 0.0026, Recall@20: 0.0043, NDCG@20: 0.0041\n",
      "Epoch 27/100, Train Loss: 0.9164, HR@20: 0.0032, Recall@20: 0.0053, NDCG@20: 0.0051\n",
      "Epoch 28/100, Train Loss: 0.9132, HR@20: 0.0039, Recall@20: 0.0066, NDCG@20: 0.0062\n",
      "Epoch 29/100, Train Loss: 0.9101, HR@20: 0.0046, Recall@20: 0.0079, NDCG@20: 0.0074\n",
      "Epoch 30/100, Train Loss: 0.9069, HR@20: 0.0054, Recall@20: 0.0095, NDCG@20: 0.0088\n",
      "Epoch 31/100, Train Loss: 0.9037, HR@20: 0.0063, Recall@20: 0.0112, NDCG@20: 0.0102\n",
      "Epoch 32/100, Train Loss: 0.9004, HR@20: 0.0072, Recall@20: 0.0130, NDCG@20: 0.0117\n",
      "Epoch 33/100, Train Loss: 0.8971, HR@20: 0.0080, Recall@20: 0.0147, NDCG@20: 0.0130\n",
      "Epoch 34/100, Train Loss: 0.8938, HR@20: 0.0088, Recall@20: 0.0162, NDCG@20: 0.0143\n",
      "Epoch 35/100, Train Loss: 0.8904, HR@20: 0.0095, Recall@20: 0.0178, NDCG@20: 0.0156\n",
      "Epoch 36/100, Train Loss: 0.8869, HR@20: 0.0101, Recall@20: 0.0192, NDCG@20: 0.0167\n",
      "Epoch 37/100, Train Loss: 0.8834, HR@20: 0.0108, Recall@20: 0.0207, NDCG@20: 0.0179\n",
      "Epoch 38/100, Train Loss: 0.8798, HR@20: 0.0114, Recall@20: 0.0220, NDCG@20: 0.0189\n",
      "Epoch 39/100, Train Loss: 0.8761, HR@20: 0.0118, Recall@20: 0.0230, NDCG@20: 0.0197\n",
      "Epoch 40/100, Train Loss: 0.8723, HR@20: 0.0123, Recall@20: 0.0241, NDCG@20: 0.0206\n",
      "Epoch 41/100, Train Loss: 0.8685, HR@20: 0.0127, Recall@20: 0.0250, NDCG@20: 0.0213\n",
      "Epoch 42/100, Train Loss: 0.8645, HR@20: 0.0131, Recall@20: 0.0260, NDCG@20: 0.0220\n",
      "Epoch 43/100, Train Loss: 0.8605, HR@20: 0.0134, Recall@20: 0.0267, NDCG@20: 0.0225\n",
      "Epoch 44/100, Train Loss: 0.8564, HR@20: 0.0136, Recall@20: 0.0274, NDCG@20: 0.0230\n",
      "Epoch 45/100, Train Loss: 0.8522, HR@20: 0.0139, Recall@20: 0.0281, NDCG@20: 0.0235\n",
      "Epoch 46/100, Train Loss: 0.8479, HR@20: 0.0142, Recall@20: 0.0287, NDCG@20: 0.0239\n",
      "Epoch 47/100, Train Loss: 0.8436, HR@20: 0.0144, Recall@20: 0.0293, NDCG@20: 0.0244\n",
      "Epoch 48/100, Train Loss: 0.8391, HR@20: 0.0146, Recall@20: 0.0299, NDCG@20: 0.0248\n",
      "Epoch 49/100, Train Loss: 0.8345, HR@20: 0.0147, Recall@20: 0.0301, NDCG@20: 0.0250\n",
      "Epoch 50/100, Train Loss: 0.8298, HR@20: 0.0148, Recall@20: 0.0305, NDCG@20: 0.0253\n",
      "Epoch 51/100, Train Loss: 0.8251, HR@20: 0.0150, Recall@20: 0.0309, NDCG@20: 0.0256\n",
      "Epoch 52/100, Train Loss: 0.8202, HR@20: 0.0151, Recall@20: 0.0312, NDCG@20: 0.0259\n",
      "Epoch 53/100, Train Loss: 0.8153, HR@20: 0.0152, Recall@20: 0.0314, NDCG@20: 0.0260\n",
      "Epoch 54/100, Train Loss: 0.8102, HR@20: 0.0153, Recall@20: 0.0317, NDCG@20: 0.0262\n",
      "Epoch 55/100, Train Loss: 0.8051, HR@20: 0.0154, Recall@20: 0.0320, NDCG@20: 0.0264\n",
      "Epoch 56/100, Train Loss: 0.7999, HR@20: 0.0155, Recall@20: 0.0321, NDCG@20: 0.0266\n",
      "Epoch 57/100, Train Loss: 0.7945, HR@20: 0.0156, Recall@20: 0.0323, NDCG@20: 0.0267\n",
      "Epoch 58/100, Train Loss: 0.7891, HR@20: 0.0157, Recall@20: 0.0326, NDCG@20: 0.0269\n",
      "Epoch 59/100, Train Loss: 0.7836, HR@20: 0.0158, Recall@20: 0.0328, NDCG@20: 0.0270\n",
      "Epoch 60/100, Train Loss: 0.7781, HR@20: 0.0158, Recall@20: 0.0330, NDCG@20: 0.0271\n",
      "Epoch 61/100, Train Loss: 0.7724, HR@20: 0.0159, Recall@20: 0.0330, NDCG@20: 0.0272\n",
      "Epoch 62/100, Train Loss: 0.7667, HR@20: 0.0159, Recall@20: 0.0331, NDCG@20: 0.0272\n",
      "Epoch 63/100, Train Loss: 0.7608, HR@20: 0.0160, Recall@20: 0.0332, NDCG@20: 0.0273\n",
      "Epoch 64/100, Train Loss: 0.7549, HR@20: 0.0160, Recall@20: 0.0333, NDCG@20: 0.0274\n",
      "Epoch 65/100, Train Loss: 0.7489, HR@20: 0.0160, Recall@20: 0.0333, NDCG@20: 0.0274\n",
      "Epoch 66/100, Train Loss: 0.7429, HR@20: 0.0161, Recall@20: 0.0334, NDCG@20: 0.0275\n",
      "Epoch 67/100, Train Loss: 0.7367, HR@20: 0.0161, Recall@20: 0.0334, NDCG@20: 0.0276\n",
      "Epoch 68/100, Train Loss: 0.7305, HR@20: 0.0161, Recall@20: 0.0334, NDCG@20: 0.0276\n",
      "Epoch 69/100, Train Loss: 0.7243, HR@20: 0.0161, Recall@20: 0.0335, NDCG@20: 0.0276\n",
      "Epoch 70/100, Train Loss: 0.7179, HR@20: 0.0161, Recall@20: 0.0335, NDCG@20: 0.0276\n",
      "Epoch 71/100, Train Loss: 0.7115, HR@20: 0.0161, Recall@20: 0.0336, NDCG@20: 0.0277\n",
      "Epoch 72/100, Train Loss: 0.7051, HR@20: 0.0162, Recall@20: 0.0337, NDCG@20: 0.0277\n",
      "Epoch 73/100, Train Loss: 0.6985, HR@20: 0.0162, Recall@20: 0.0338, NDCG@20: 0.0278\n",
      "Epoch 74/100, Train Loss: 0.6919, HR@20: 0.0162, Recall@20: 0.0338, NDCG@20: 0.0278\n",
      "Epoch 75/100, Train Loss: 0.6853, HR@20: 0.0162, Recall@20: 0.0339, NDCG@20: 0.0279\n",
      "Epoch 76/100, Train Loss: 0.6786, HR@20: 0.0163, Recall@20: 0.0339, NDCG@20: 0.0279\n",
      "Epoch 77/100, Train Loss: 0.6719, HR@20: 0.0163, Recall@20: 0.0339, NDCG@20: 0.0279\n",
      "Epoch 78/100, Train Loss: 0.6651, HR@20: 0.0163, Recall@20: 0.0339, NDCG@20: 0.0279\n",
      "Epoch 79/100, Train Loss: 0.6582, HR@20: 0.0163, Recall@20: 0.0340, NDCG@20: 0.0280\n",
      "Epoch 80/100, Train Loss: 0.6513, HR@20: 0.0163, Recall@20: 0.0340, NDCG@20: 0.0280\n",
      "Epoch 81/100, Train Loss: 0.6444, HR@20: 0.0163, Recall@20: 0.0340, NDCG@20: 0.0281\n",
      "Epoch 82/100, Train Loss: 0.6374, HR@20: 0.0163, Recall@20: 0.0340, NDCG@20: 0.0281\n",
      "Epoch 83/100, Train Loss: 0.6304, HR@20: 0.0163, Recall@20: 0.0340, NDCG@20: 0.0281\n",
      "Epoch 84/100, Train Loss: 0.6234, HR@20: 0.0164, Recall@20: 0.0341, NDCG@20: 0.0281\n",
      "Epoch 85/100, Train Loss: 0.6163, HR@20: 0.0164, Recall@20: 0.0341, NDCG@20: 0.0281\n",
      "Epoch 86/100, Train Loss: 0.6092, HR@20: 0.0164, Recall@20: 0.0342, NDCG@20: 0.0281\n",
      "Epoch 87/100, Train Loss: 0.6020, HR@20: 0.0164, Recall@20: 0.0342, NDCG@20: 0.0282\n",
      "Epoch 88/100, Train Loss: 0.5949, HR@20: 0.0164, Recall@20: 0.0343, NDCG@20: 0.0282\n",
      "Epoch 89/100, Train Loss: 0.5877, HR@20: 0.0165, Recall@20: 0.0343, NDCG@20: 0.0282\n",
      "Epoch 90/100, Train Loss: 0.5805, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 91/100, Train Loss: 0.5732, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 92/100, Train Loss: 0.5660, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 93/100, Train Loss: 0.5588, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 94/100, Train Loss: 0.5515, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 95/100, Train Loss: 0.5442, HR@20: 0.0165, Recall@20: 0.0344, NDCG@20: 0.0283\n",
      "Epoch 96/100, Train Loss: 0.5369, HR@20: 0.0165, Recall@20: 0.0345, NDCG@20: 0.0284\n",
      "Epoch 97/100, Train Loss: 0.5297, HR@20: 0.0165, Recall@20: 0.0345, NDCG@20: 0.0284\n",
      "Epoch 98/100, Train Loss: 0.5224, HR@20: 0.0165, Recall@20: 0.0345, NDCG@20: 0.0284\n",
      "Epoch 99/100, Train Loss: 0.5151, HR@20: 0.0165, Recall@20: 0.0345, NDCG@20: 0.0284\n",
      "Epoch 100/100, Train Loss: 0.5078, HR@20: 0.0165, Recall@20: 0.0345, NDCG@20: 0.0284\n",
      "Total time: 1746.92s\n"
     ]
    }
   ],
   "source": [
    "model, recall, ndcg = MF_based_eva(model, config, data, device)\n",
    "# Store the model parameters\n",
    "torch.save(model.state_dict(), f\"MF_Yelp2018_{config['epochs']}_Epochs_Top_{config['k']}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
