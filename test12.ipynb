{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.MF import *\n",
    "from preprocess.AmazonBook import *\n",
    "from evaluation.MF_SISA import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/amazon-book'\n",
    "dataset = AmazonBook(path)\n",
    "\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'lr': 1e-4, \n",
    "    'epochs': 100,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 8192,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "    \"weight_decay\": 1e-7,\n",
    "    'global_bias':(data.edge_index.size(1) + data.edge_label_index.size(1) + 2) / (num_books * num_users)\n",
    "}\n",
    "model = MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df800181e611fe3e",
   "metadata": {},
   "source": [
    "# SISA Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7666a877cb7c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9945, HR@20: 0.0001, Recall@20: 0.0003, NDCG@20: 0.0002\n",
      "Epoch: 002, Loss: 0.9844, HR@20: 0.0001, Recall@20: 0.0003, NDCG@20: 0.0002\n",
      "Epoch: 003, Loss: 0.9743, HR@20: 0.0002, Recall@20: 0.0003, NDCG@20: 0.0003\n",
      "Epoch: 004, Loss: 0.9642, HR@20: 0.0002, Recall@20: 0.0004, NDCG@20: 0.0003\n",
      "Epoch: 005, Loss: 0.9541, HR@20: 0.0003, Recall@20: 0.0006, NDCG@20: 0.0005\n",
      "Epoch: 006, Loss: 0.9438, HR@20: 0.0005, Recall@20: 0.0009, NDCG@20: 0.0008\n",
      "Epoch: 007, Loss: 0.9333, HR@20: 0.0007, Recall@20: 0.0014, NDCG@20: 0.0013\n",
      "Epoch: 008, Loss: 0.9226, HR@20: 0.0011, Recall@20: 0.0020, NDCG@20: 0.0018\n",
      "Epoch: 009, Loss: 0.9116, HR@20: 0.0015, Recall@20: 0.0027, NDCG@20: 0.0024\n",
      "Epoch: 010, Loss: 0.9001, HR@20: 0.0018, Recall@20: 0.0034, NDCG@20: 0.0030\n",
      "Epoch: 011, Loss: 0.8882, HR@20: 0.0022, Recall@20: 0.0040, NDCG@20: 0.0036\n",
      "Epoch: 012, Loss: 0.8758, HR@20: 0.0025, Recall@20: 0.0047, NDCG@20: 0.0041\n",
      "Epoch: 013, Loss: 0.8629, HR@20: 0.0027, Recall@20: 0.0051, NDCG@20: 0.0044\n",
      "Epoch: 014, Loss: 0.8494, HR@20: 0.0029, Recall@20: 0.0055, NDCG@20: 0.0047\n",
      "Epoch: 015, Loss: 0.8352, HR@20: 0.0031, Recall@20: 0.0057, NDCG@20: 0.0050\n",
      "Epoch: 016, Loss: 0.8205, HR@20: 0.0032, Recall@20: 0.0060, NDCG@20: 0.0053\n",
      "Epoch: 017, Loss: 0.8051, HR@20: 0.0034, Recall@20: 0.0064, NDCG@20: 0.0055\n",
      "Epoch: 018, Loss: 0.7892, HR@20: 0.0035, Recall@20: 0.0066, NDCG@20: 0.0057\n",
      "Epoch: 019, Loss: 0.7727, HR@20: 0.0036, Recall@20: 0.0068, NDCG@20: 0.0059\n",
      "Epoch: 020, Loss: 0.7557, HR@20: 0.0037, Recall@20: 0.0070, NDCG@20: 0.0060\n",
      "Epoch: 021, Loss: 0.7382, HR@20: 0.0038, Recall@20: 0.0072, NDCG@20: 0.0062\n",
      "Epoch: 022, Loss: 0.7203, HR@20: 0.0039, Recall@20: 0.0073, NDCG@20: 0.0063\n",
      "Epoch: 023, Loss: 0.7019, HR@20: 0.0039, Recall@20: 0.0075, NDCG@20: 0.0064\n",
      "Epoch: 024, Loss: 0.6833, HR@20: 0.0040, Recall@20: 0.0076, NDCG@20: 0.0065\n",
      "Epoch: 025, Loss: 0.6644, HR@20: 0.0041, Recall@20: 0.0077, NDCG@20: 0.0066\n",
      "Epoch: 026, Loss: 0.6453, HR@20: 0.0041, Recall@20: 0.0078, NDCG@20: 0.0067\n",
      "Epoch: 027, Loss: 0.6261, HR@20: 0.0042, Recall@20: 0.0079, NDCG@20: 0.0068\n",
      "Epoch: 028, Loss: 0.6068, HR@20: 0.0042, Recall@20: 0.0081, NDCG@20: 0.0069\n",
      "Epoch: 029, Loss: 0.5875, HR@20: 0.0043, Recall@20: 0.0082, NDCG@20: 0.0070\n",
      "Epoch: 030, Loss: 0.5682, HR@20: 0.0044, Recall@20: 0.0083, NDCG@20: 0.0071\n",
      "Epoch: 031, Loss: 0.5490, HR@20: 0.0044, Recall@20: 0.0084, NDCG@20: 0.0071\n",
      "Epoch: 032, Loss: 0.5300, HR@20: 0.0044, Recall@20: 0.0085, NDCG@20: 0.0072\n",
      "Epoch: 033, Loss: 0.5111, HR@20: 0.0045, Recall@20: 0.0086, NDCG@20: 0.0073\n",
      "Epoch: 034, Loss: 0.4925, HR@20: 0.0045, Recall@20: 0.0087, NDCG@20: 0.0074\n",
      "Epoch: 035, Loss: 0.4742, HR@20: 0.0046, Recall@20: 0.0088, NDCG@20: 0.0075\n",
      "Epoch: 036, Loss: 0.4562, HR@20: 0.0047, Recall@20: 0.0089, NDCG@20: 0.0076\n",
      "Epoch: 037, Loss: 0.4386, HR@20: 0.0047, Recall@20: 0.0090, NDCG@20: 0.0077\n",
      "Epoch: 038, Loss: 0.4213, HR@20: 0.0047, Recall@20: 0.0091, NDCG@20: 0.0077\n",
      "Epoch: 039, Loss: 0.4044, HR@20: 0.0048, Recall@20: 0.0092, NDCG@20: 0.0078\n",
      "Epoch: 040, Loss: 0.3880, HR@20: 0.0048, Recall@20: 0.0093, NDCG@20: 0.0079\n",
      "Epoch: 041, Loss: 0.3720, HR@20: 0.0049, Recall@20: 0.0094, NDCG@20: 0.0080\n",
      "Epoch: 042, Loss: 0.3564, HR@20: 0.0049, Recall@20: 0.0096, NDCG@20: 0.0081\n",
      "Epoch: 043, Loss: 0.3413, HR@20: 0.0050, Recall@20: 0.0097, NDCG@20: 0.0082\n",
      "Epoch: 044, Loss: 0.3266, HR@20: 0.0050, Recall@20: 0.0098, NDCG@20: 0.0083\n",
      "Epoch: 045, Loss: 0.3124, HR@20: 0.0050, Recall@20: 0.0099, NDCG@20: 0.0084\n",
      "Epoch: 046, Loss: 0.2987, HR@20: 0.0051, Recall@20: 0.0100, NDCG@20: 0.0085\n",
      "Epoch: 047, Loss: 0.2855, HR@20: 0.0051, Recall@20: 0.0101, NDCG@20: 0.0086\n",
      "Epoch: 048, Loss: 0.2727, HR@20: 0.0051, Recall@20: 0.0101, NDCG@20: 0.0087\n",
      "Epoch: 049, Loss: 0.2603, HR@20: 0.0051, Recall@20: 0.0101, NDCG@20: 0.0087\n",
      "Epoch: 050, Loss: 0.2484, HR@20: 0.0051, Recall@20: 0.0101, NDCG@20: 0.0088\n",
      "Epoch: 051, Loss: 0.2370, HR@20: 0.0051, Recall@20: 0.0102, NDCG@20: 0.0088\n",
      "Epoch: 052, Loss: 0.2260, HR@20: 0.0051, Recall@20: 0.0102, NDCG@20: 0.0089\n",
      "Epoch: 053, Loss: 0.2154, HR@20: 0.0051, Recall@20: 0.0103, NDCG@20: 0.0089\n",
      "Epoch: 054, Loss: 0.2053, HR@20: 0.0052, Recall@20: 0.0103, NDCG@20: 0.0090\n",
      "Epoch: 055, Loss: 0.1956, HR@20: 0.0052, Recall@20: 0.0103, NDCG@20: 0.0089\n",
      "Epoch: 056, Loss: 0.1862, HR@20: 0.0052, Recall@20: 0.0103, NDCG@20: 0.0089\n",
      "Epoch: 057, Loss: 0.1773, HR@20: 0.0052, Recall@20: 0.0103, NDCG@20: 0.0089\n",
      "Epoch: 058, Loss: 0.1687, HR@20: 0.0052, Recall@20: 0.0103, NDCG@20: 0.0089\n",
      "Epoch: 059, Loss: 0.1605, HR@20: 0.0051, Recall@20: 0.0102, NDCG@20: 0.0088\n",
      "Epoch: 060, Loss: 0.1526, HR@20: 0.0051, Recall@20: 0.0101, NDCG@20: 0.0087\n"
     ]
    }
   ],
   "source": [
    "config['epochs'] = 60  # enough to converge\n",
    "config['num_shards'] = 5\n",
    "model_list =[]\n",
    "\n",
    "for _ in range(config['num_shards']):\n",
    "    model_list.append(MF(\n",
    "    num_users= config['num_users'],\n",
    "    num_items= config['num_books'],\n",
    "    mean = config['global_bias'],\n",
    "    embedding_dim = config['embedding_dim']\n",
    ").to(device))\n",
    "\n",
    "shard_models, shards, epoch_tracks, test_topks = sisa_MF_eva(model_list, config, data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd6bfd854d2080",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde99a93b7e70ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m forget_data\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_nodes\n\u001b[0;32m     11\u001b[0m retain_data\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_nodes\n\u001b[1;32m---> 12\u001b[0m forget_data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m retain_data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index[:, perm[split:]]\n\u001b[0;32m     14\u001b[0m forget_data\u001b[38;5;241m.\u001b[39medge_label_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_label_index\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Basic setting\n",
    "num_edges = data.edge_index.size(1)\n",
    "perm = torch.randperm(num_edges)\n",
    "split = int(num_edges * 0.1)  # 10% of edges will be retained\n",
    "\n",
    "# Define the data for forget and retain dataset\n",
    "forget_data = Data()\n",
    "retain_data = Data()\n",
    "\n",
    "forget_data.num_nodes = data.num_nodes\n",
    "retain_data.num_nodes = data.num_nodes\n",
    "forget_data.edge_index = data.edge_index[:, perm[:split]]\n",
    "retain_data.edge_index = data.edge_index[:, perm[split:]]\n",
    "forget_data.edge_label_index = data.edge_label_index\n",
    "retain_data.edge_label_index = data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553bb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m shard_models \u001b[38;5;241m=\u001b[39m \u001b[43msisa_MF_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\MF_SISA.py:106\u001b[0m, in \u001b[0;36msisa_MF_unlearning_eva\u001b[1;34m(shard_models, shards, retain_data, forget_data, config, device)\u001b[0m\n",
      "\u001b[0;32m    104\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_shards\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m    105\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m--> 106\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m    107\u001b[0m train_edge_index \u001b[38;5;241m=\u001b[39m retain_data\u001b[38;5;241m.\u001b[39medge_index[:, mask]\n",
      "\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# retain_data.to(device)\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "shard_models = sisa_MF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e0d2c35707aa8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m shard_models \u001b[38;5;241m=\u001b[39m \u001b[43msisa_MF_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\MF_SISA.py:106\u001b[0m, in \u001b[0;36msisa_MF_unlearning_eva\u001b[1;34m(shard_models, shards, retain_data, forget_data, config, device)\u001b[0m\n\u001b[0;32m    104\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_shards\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    105\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 106\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    107\u001b[0m train_edge_index \u001b[38;5;241m=\u001b[39m retain_data\u001b[38;5;241m.\u001b[39medge_index[:, mask]\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# retain_data.to(device)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "shard_models = sisa_MF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290b2e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m shard_models \u001b[38;5;241m=\u001b[39m \u001b[43msisa_MF_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\MF_SISA.py:106\u001b[0m, in \u001b[0;36msisa_MF_unlearning_eva\u001b[1;34m(shard_models, shards, retain_data, forget_data, config, device)\u001b[0m\n",
      "\u001b[0;32m    104\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_shards\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m    105\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m--> 106\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m    107\u001b[0m train_edge_index \u001b[38;5;241m=\u001b[39m retain_data\u001b[38;5;241m.\u001b[39medge_index[:, mask]\n",
      "\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# retain_data.to(device)\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "shard_models = sisa_MF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180483a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m shard_models \u001b[38;5;241m=\u001b[39m \u001b[43msisa_MF_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\MF_SISA.py:106\u001b[0m, in \u001b[0;36msisa_MF_unlearning_eva\u001b[1;34m(shard_models, shards, retain_data, forget_data, config, device)\u001b[0m\n",
      "\u001b[0;32m    104\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_shards\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m    105\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m--> 106\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m    107\u001b[0m train_edge_index \u001b[38;5;241m=\u001b[39m retain_data\u001b[38;5;241m.\u001b[39medge_index[:, mask]\n",
      "\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# retain_data.to(device)\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "shard_models = sisa_MF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18923b57",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m shard_models \u001b[38;5;241m=\u001b[39m \u001b[43msisa_MF_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\MF_SISA.py:106\u001b[0m, in \u001b[0;36msisa_MF_unlearning_eva\u001b[1;34m(shard_models, shards, retain_data, forget_data, config, device)\u001b[0m\n",
      "\u001b[0;32m    104\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_shards\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m    105\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m--> 106\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m    107\u001b[0m train_edge_index \u001b[38;5;241m=\u001b[39m retain_data\u001b[38;5;241m.\u001b[39medge_index[:, mask]\n",
      "\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# retain_data.to(device)\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "shard_models = sisa_MF_unlearning_eva(shard_models, shards, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bda065fb48996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisa_MF_forget_data_eva(shard_models, forget_data, config, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
