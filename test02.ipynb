{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20206a4c5d4606a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T07:10:28.256306Z",
     "start_time": "2024-10-26T07:10:26.147534Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.LightGCN import *\n",
    "from preprocess.AmazonBook import *\n",
    "from evaluation.LightGCN_evaluation import *\n",
    "from evaluation.LightGCN_SISA import *\n",
    "pd.options.display.max_rows = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = './dataset/amazon-book'\n",
    "dataset = AmazonBook(path)\n",
    "\n",
    "data = dataset.get()\n",
    "num_users, num_books = dataset.getNumber()\n",
    "config = {\n",
    "    'k': 20,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 1000,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 2048,\n",
    "    'embedding_dim': 64,\n",
    "    'num_users': num_users,\n",
    "    'num_books': num_books,\n",
    "    'tuning_type': None,\n",
    "}\n",
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eca03bc955dbf9",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883de21e2673a1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T07:10:30.625427Z",
     "start_time": "2024-10-26T07:10:30.567975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic setting\n",
    "num_edges = data.edge_index.size(1)\n",
    "perm = torch.randperm(num_edges)\n",
    "split = int(num_edges * 0.1)  # 10% of edges will be retained\n",
    "\n",
    "# Define the data for forget and retain dataset\n",
    "forget_data = Data()\n",
    "retain_data = Data()\n",
    "\n",
    "forget_data.num_nodes = data.num_nodes\n",
    "retain_data.num_nodes = data.num_nodes\n",
    "forget_data.edge_index = data.edge_index[:, perm[:split]]\n",
    "retain_data.edge_index = data.edge_index[:, perm[split:]]\n",
    "forget_data.edge_label_index = data.edge_label_index\n",
    "retain_data.edge_label_index = data.edge_label_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c1b4dc53b4a4d",
   "metadata": {},
   "source": [
    "# Retain LightGCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81cdf1b8c2bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['epochs'] = 1000\n",
    "retrain_lightgcn = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    ").to(device)\n",
    "retrain_lightgcn, epoch_tracks, test_topks = lightgcn_eva(retrain_lightgcn, config, retain_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b599b62867d1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(retrain_lightgcn, None, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c81335a68a343",
   "metadata": {},
   "source": [
    "# Prompt Unlearning\n",
    "## Case 1: Without Contrastive Loss and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994827eac306105a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T07:10:35.533602Z",
     "start_time": "2024-10-26T07:10:34.609152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "teacher = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    ").to(device)\n",
    "student = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    ").to(device)\n",
    "\n",
    "# Load the model\n",
    "teacher.load_state_dict(torch.load(f\"lightGCN_Amazon_Book_{config['epochs']}_Epochs.pt\"))\n",
    "student.load_state_dict(torch.load(f\"lightGCN_Amazon_Book_{config['epochs']}_Epochs.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a081437da4318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T07:33:54.394079Z",
     "start_time": "2024-10-26T07:10:39.029586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\.conda\\envs\\master\\lib\\site-packages\\torch_geometric\\data\\storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_label_index', 'edge_index', 'x'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5510, HR@20: 0.0142, Recall@20: 0.0341, NDCG@20: 0.0257\n",
      "Epoch: 002, Loss: 0.5083, HR@20: 0.0142, Recall@20: 0.0340, NDCG@20: 0.0257\n",
      "Epoch: 003, Loss: 0.4508, HR@20: 0.0142, Recall@20: 0.0339, NDCG@20: 0.0257\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContrastive_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m student, prompt, epoch_tracks, test_topks \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_lightgcn_unlearning_eva\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\evaluation\\LightGCN_evaluation.py:253\u001b[0m, in \u001b[0;36mprompt_lightgcn_unlearning_eva\u001b[1;34m(teacher, student, retain_data, forget_data, config, device)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m node_count[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m             ndcg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mndcg_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision \u001b[38;5;241m/\u001b[39m total_examples\n\u001b[0;32m    255\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall \u001b[38;5;241m/\u001b[39m total_examples\n",
      "File \u001b[1;32md:\\Programming\\Project\\promptGraph\\util\\LightGCN.py:304\u001b[0m, in \u001b[0;36mndcg_at_k\u001b[1;34m(predictions, ground_truth, k)\u001b[0m\n\u001b[0;32m    301\u001b[0m top_k_true_relevance \u001b[38;5;241m=\u001b[39m ground_truth[top_k_idxs]\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# 计算折扣因子\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m discounts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mground_truth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# 计算DCG\u001b[39;00m\n\u001b[0;32m    307\u001b[0m dcg_k \u001b[38;5;241m=\u001b[39m (top_k_true_relevance \u001b[38;5;241m*\u001b[39m discounts)\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['beta'] = 0.7\n",
    "config['alpha'] = 0.3\n",
    "config['epochs'] = 10\n",
    "config['gamma'] = 1e-6 # contrastive loss\n",
    "config['delta'] = 1e-3 # regularization loss\n",
    "config['tuning_type'] = 'gpf'\n",
    "config['weight_decay'] = 0.001\n",
    "config['regularization'] = False\n",
    "config['Contrastive_loss'] = False\n",
    "student, prompt, epoch_tracks, test_topks = prompt_lightgcn_unlearning_eva(teacher, student, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53b50a7f827ff5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:12:02.316259Z",
     "start_time": "2024-09-20T10:11:56.232391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0268, Recall@20: 0.1552, NDCG@20: 0.1597\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(student, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f0c2dad028d61",
   "metadata": {},
   "source": [
    "## Case 2: Without Contrastive Loss but with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddaaa49f2857d3fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:18:54.167482Z",
     "start_time": "2024-09-20T10:12:14.124387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5698, HR@20: 0.0137, Recall@20: 0.0329, NDCG@20: 0.0805\n",
      "Epoch: 002, Loss: 0.5404, HR@20: 0.0136, Recall@20: 0.0326, NDCG@20: 0.0799\n",
      "Epoch: 003, Loss: 0.4984, HR@20: 0.0135, Recall@20: 0.0325, NDCG@20: 0.0794\n",
      "Epoch: 004, Loss: 0.4570, HR@20: 0.0135, Recall@20: 0.0323, NDCG@20: 0.0789\n",
      "Epoch: 005, Loss: 0.4293, HR@20: 0.0135, Recall@20: 0.0323, NDCG@20: 0.0788\n",
      "Epoch: 006, Loss: 0.3971, HR@20: 0.0134, Recall@20: 0.0322, NDCG@20: 0.0787\n",
      "Epoch: 007, Loss: 0.3756, HR@20: 0.0134, Recall@20: 0.0323, NDCG@20: 0.0786\n",
      "Epoch: 008, Loss: 0.3582, HR@20: 0.0134, Recall@20: 0.0323, NDCG@20: 0.0786\n",
      "Epoch: 009, Loss: 0.3388, HR@20: 0.0134, Recall@20: 0.0323, NDCG@20: 0.0786\n",
      "Epoch: 010, Loss: 0.3256, HR@20: 0.0135, Recall@20: 0.0324, NDCG@20: 0.0786\n",
      "Total time: 208.20s\n"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = False\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_lightgcn_unlearning_eva(teacher, student, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28834b07635a3421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:19:00.159084Z",
     "start_time": "2024-09-20T10:18:54.167482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0255, Recall@20: 0.1472, NDCG@20: 0.1534\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(student, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d56748129057a",
   "metadata": {},
   "source": [
    "## Case 3: With Contrastive Loss but without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884d52b748a06f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:25:58.817164Z",
     "start_time": "2024-09-20T10:19:20.575295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['beta'] = 0.7\n",
    "config['alpha'] = 0.3\n",
    "config['epochs'] = 10\n",
    "config['gamma'] = 1e-6 # contrastive loss\n",
    "config['delta'] = 1e-3 # regularization loss\n",
    "config['tuning_type'] = 'gpf'\n",
    "config['weight_decay'] = 0.001\n",
    "# Setting the basic hyperparameters\n",
    "config['Contrastive_loss'] = True\n",
    "config['regularization'] = False\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_lightgcn_unlearning_eva(teacher, student, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fdc7e1e2c418011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:26:04.816037Z",
     "start_time": "2024-09-20T10:25:58.817164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0243, Recall@20: 0.1375\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(student, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e397025819fd649",
   "metadata": {},
   "source": [
    "## Case 4: With Contrastive Loss and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9c9b2868f7b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:33:51.285443Z",
     "start_time": "2024-09-20T10:27:13.464984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6785, HR@20: 0.0138, Recall@20: 0.0330\n",
      "Epoch: 002, Loss: 0.6717, HR@20: 0.0138, Recall@20: 0.0330\n",
      "Epoch: 003, Loss: 0.6621, HR@20: 0.0138, Recall@20: 0.0331\n",
      "Epoch: 004, Loss: 0.6501, HR@20: 0.0138, Recall@20: 0.0332\n",
      "Epoch: 005, Loss: 0.6356, HR@20: 0.0138, Recall@20: 0.0332\n",
      "Epoch: 006, Loss: 0.6257, HR@20: 0.0139, Recall@20: 0.0333\n",
      "Epoch: 007, Loss: 0.6112, HR@20: 0.0139, Recall@20: 0.0334\n",
      "Epoch: 008, Loss: 0.6016, HR@20: 0.0140, Recall@20: 0.0335\n",
      "Epoch: 009, Loss: 0.5831, HR@20: 0.0140, Recall@20: 0.0335\n",
      "Epoch: 010, Loss: 0.5750, HR@20: 0.0140, Recall@20: 0.0336\n",
      "Epoch: 011, Loss: 0.5642, HR@20: 0.0140, Recall@20: 0.0336\n",
      "Epoch: 012, Loss: 0.5614, HR@20: 0.0140, Recall@20: 0.0337\n",
      "Epoch: 013, Loss: 0.5561, HR@20: 0.0140, Recall@20: 0.0337\n",
      "Epoch: 014, Loss: 0.5462, HR@20: 0.0140, Recall@20: 0.0337\n",
      "Epoch: 015, Loss: 0.5493, HR@20: 0.0141, Recall@20: 0.0338\n",
      "Epoch: 016, Loss: 0.5459, HR@20: 0.0141, Recall@20: 0.0338\n",
      "Epoch: 017, Loss: 0.5430, HR@20: 0.0141, Recall@20: 0.0338\n",
      "Epoch: 018, Loss: 0.5428, HR@20: 0.0141, Recall@20: 0.0338\n",
      "Epoch: 019, Loss: 0.5323, HR@20: 0.0141, Recall@20: 0.0339\n",
      "Epoch: 020, Loss: 0.5323, HR@20: 0.0142, Recall@20: 0.0339\n",
      "Epoch: 021, Loss: 0.5291, HR@20: 0.0142, Recall@20: 0.0340\n",
      "Epoch: 022, Loss: 0.5269, HR@20: 0.0142, Recall@20: 0.0340\n",
      "Epoch: 023, Loss: 0.5264, HR@20: 0.0142, Recall@20: 0.0340\n",
      "Epoch: 024, Loss: 0.5207, HR@20: 0.0142, Recall@20: 0.0340\n",
      "Epoch: 025, Loss: 0.5169, HR@20: 0.0142, Recall@20: 0.0341\n",
      "Epoch: 026, Loss: 0.5207, HR@20: 0.0142, Recall@20: 0.0341\n",
      "Epoch: 027, Loss: 0.5117, HR@20: 0.0142, Recall@20: 0.0341\n",
      "Epoch: 028, Loss: 0.5140, HR@20: 0.0142, Recall@20: 0.0341\n",
      "Epoch: 029, Loss: 0.5092, HR@20: 0.0142, Recall@20: 0.0341\n",
      "Epoch: 030, Loss: 0.5118, HR@20: 0.0143, Recall@20: 0.0342\n",
      "Epoch: 031, Loss: 0.5078, HR@20: 0.0143, Recall@20: 0.0343\n",
      "Epoch: 032, Loss: 0.5029, HR@20: 0.0143, Recall@20: 0.0343\n",
      "Epoch: 033, Loss: 0.4931, HR@20: 0.0143, Recall@20: 0.0344\n",
      "Epoch: 034, Loss: 0.4907, HR@20: 0.0143, Recall@20: 0.0344\n",
      "Epoch: 035, Loss: 0.4997, HR@20: 0.0144, Recall@20: 0.0344\n",
      "Epoch: 036, Loss: 0.4927, HR@20: 0.0144, Recall@20: 0.0345\n",
      "Epoch: 037, Loss: 0.4846, HR@20: 0.0144, Recall@20: 0.0344\n",
      "Epoch: 038, Loss: 0.4798, HR@20: 0.0144, Recall@20: 0.0344\n",
      "Epoch: 039, Loss: 0.4780, HR@20: 0.0144, Recall@20: 0.0344\n",
      "Epoch: 040, Loss: 0.4788, HR@20: 0.0144, Recall@20: 0.0344\n",
      "Epoch: 041, Loss: 0.4711, HR@20: 0.0144, Recall@20: 0.0345\n",
      "Epoch: 042, Loss: 0.4744, HR@20: 0.0144, Recall@20: 0.0345\n",
      "Epoch: 043, Loss: 0.4699, HR@20: 0.0144, Recall@20: 0.0345\n",
      "Epoch: 044, Loss: 0.4677, HR@20: 0.0144, Recall@20: 0.0346\n",
      "Epoch: 045, Loss: 0.4611, HR@20: 0.0144, Recall@20: 0.0346\n",
      "Epoch: 046, Loss: 0.4599, HR@20: 0.0144, Recall@20: 0.0346\n",
      "Epoch: 047, Loss: 0.4622, HR@20: 0.0145, Recall@20: 0.0347\n",
      "Epoch: 048, Loss: 0.4522, HR@20: 0.0145, Recall@20: 0.0347\n",
      "Epoch: 049, Loss: 0.4479, HR@20: 0.0145, Recall@20: 0.0347\n",
      "Epoch: 050, Loss: 0.4456, HR@20: 0.0145, Recall@20: 0.0347\n",
      "Running time: 397.8048\n"
     ]
    }
   ],
   "source": [
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_lightgcn_unlearning_eva(teacher, student, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7df3bea2fa78f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:33:57.272888Z",
     "start_time": "2024-09-20T10:33:51.285443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0253, Recall@20: 0.1448\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(student, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0df91690ebf0f",
   "metadata": {},
   "source": [
    "# Additional Materials(Multiple Prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f70feba5a062c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:41:06.761569Z",
     "start_time": "2024-09-20T10:34:24.679634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6978, HR@20: 0.0139, Recall@20: 0.0333\n",
      "Epoch: 002, Loss: 0.6803, HR@20: 0.0138, Recall@20: 0.0330\n",
      "Epoch: 003, Loss: 0.6519, HR@20: 0.0137, Recall@20: 0.0328\n",
      "Epoch: 004, Loss: 0.6215, HR@20: 0.0137, Recall@20: 0.0327\n",
      "Epoch: 005, Loss: 0.6013, HR@20: 0.0136, Recall@20: 0.0326\n",
      "Epoch: 006, Loss: 0.5859, HR@20: 0.0137, Recall@20: 0.0326\n",
      "Epoch: 007, Loss: 0.5516, HR@20: 0.0137, Recall@20: 0.0327\n",
      "Epoch: 008, Loss: 0.5351, HR@20: 0.0137, Recall@20: 0.0327\n",
      "Epoch: 009, Loss: 0.5281, HR@20: 0.0138, Recall@20: 0.0328\n",
      "Epoch: 010, Loss: 0.5232, HR@20: 0.0137, Recall@20: 0.0329\n",
      "Epoch: 011, Loss: 0.4904, HR@20: 0.0138, Recall@20: 0.0330\n",
      "Epoch: 012, Loss: 0.4740, HR@20: 0.0138, Recall@20: 0.0332\n",
      "Epoch: 013, Loss: 0.4466, HR@20: 0.0139, Recall@20: 0.0333\n",
      "Epoch: 014, Loss: 0.4162, HR@20: 0.0139, Recall@20: 0.0333\n",
      "Epoch: 015, Loss: 0.4063, HR@20: 0.0138, Recall@20: 0.0332\n",
      "Epoch: 016, Loss: 0.3676, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 017, Loss: 0.3472, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 018, Loss: 0.3212, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 019, Loss: 0.3220, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 020, Loss: 0.3297, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 021, Loss: 0.2993, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 022, Loss: 0.3183, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 023, Loss: 0.2941, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 024, Loss: 0.2799, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 025, Loss: 0.2886, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 026, Loss: 0.2992, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 027, Loss: 0.2868, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 028, Loss: 0.2749, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 029, Loss: 0.2791, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 030, Loss: 0.2690, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 031, Loss: 0.2686, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 032, Loss: 0.2287, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 033, Loss: 0.2484, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 034, Loss: 0.2811, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 035, Loss: 0.2466, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 036, Loss: 0.2767, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 037, Loss: 0.2711, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 038, Loss: 0.2276, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 039, Loss: 0.2128, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 040, Loss: 0.2332, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 041, Loss: 0.2519, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 042, Loss: 0.2482, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 043, Loss: 0.1872, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 044, Loss: 0.2087, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 045, Loss: 0.1915, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 046, Loss: 0.2256, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 047, Loss: 0.2477, HR@20: 0.0139, Recall@20: 0.0337\n",
      "Epoch: 048, Loss: 0.1989, HR@20: 0.0139, Recall@20: 0.0335\n",
      "Epoch: 049, Loss: 0.1991, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Epoch: 050, Loss: 0.2009, HR@20: 0.0139, Recall@20: 0.0336\n",
      "Running time: 402.0498\n"
     ]
    }
   ],
   "source": [
    "config['tuning_type'] = 'gpf-plus'\n",
    "config[\"number_p\"] = 10 # The number of prompts\n",
    "# Setting the basic hyperparameters\n",
    "config['contrastive_loss'] = True\n",
    "config['regularization'] = True\n",
    "\n",
    "student, prompt, epoch_tracks, test_topks = prompt_lightgcn_unlearning_eva(teacher, student, retain_data, forget_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e40a8d33adb558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:41:12.755562Z",
     "start_time": "2024-09-20T10:41:06.761569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0255, Recall@20: 0.1462\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(student, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3cb66651da651e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T10:42:28.148070Z",
     "start_time": "2024-09-20T10:42:21.798785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.0255, Recall@20: 0.1462\n"
     ]
    }
   ],
   "source": [
    "# Test on the forget data\n",
    "lightgcn_forget_data_eva(teacher, prompt, forget_data, config['num_users'], config['k'], config['batch_size'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa7af8d4b4344e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
